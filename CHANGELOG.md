# Changelog

Alle wichtigen √Ñnderungen an AIfred Intelligence werden in dieser Datei dokumentiert.

Format basiert auf [Keep a Changelog](https://keepachangelog.com/de/1.0.0/).

---

## [2025-10-25] - Cache-Fixes, Debug-Logging & UI-Verbesserungen

### üéØ Hinzugef√ºgt

#### File-Based Debug Logging System
- **Neues Debug-Log-System** in `lib/logging_utils.py`
  - Alle Debug-Ausgaben gehen jetzt in `logs/aifred_debug.log` (nicht mehr Journal Control)
  - **Automatische Log-Rotation**: Bei >1 MB wird rotiert (alte Datei ‚Üí `.old`, neue erstellt)
  - **Timestamp-Format**: `HH:MM:SS.mmm` f√ºr pr√§zises Timing
  - **√úberschreiben bei Service-Start**: Jeder Service-Neustart startet mit leerem Log
  - **Append bei Browser-Reload**: Mehrere Tests hintereinander bleiben sichtbar
  - **Maximale Gr√∂√üe**: 1 MB = ~20-30 Anfragen (√ºberschaubar zum Debuggen)

#### Intelligente Scraping-Strategie
- **Download-Failed Detection** in `lib/agent_tools.py`:
  - Wenn Trafilatura Download fehlschl√§gt (404, Timeout, Bot-Protection) ‚Üí **KEIN Playwright Retry**
  - Spart ~10s Timeout pro blockierter Site (z.B. AccuWeather)
  - Nur bei erfolgreichem Download mit wenig Content (< 1000 W√∂rter) ‚Üí Playwright Fallback
- **AccuWeather Timeout-Problem gel√∂st**: Von 43s auf sofortigen Skip reduziert

#### Umfassendes Cache-Debug-Logging
- **Cache-Lookup Logging** in `lib/agent_core.py` (Zeilen 78-90):
  - Zeigt bei jedem Lookup: Gesuchte Session-ID, Cache-Eintr√§ge, Hit/Miss Status
  - Format: `üîç DEBUG Cache-Lookup: Suche session_id = 71ccc280...`
  - Bei Hit: `‚úÖ Cache-Hit! Eintrag gefunden mit 3 Quellen`
  - Bei Miss: `‚ùå Cache-Miss! session_id '71ccc280...' nicht in Cache`

- **Kompletter Cache-Dump** in `lib/agent_core.py` (Zeilen 228-242):
  - Nach jedem Cache-Save: Zeigt GESAMTEN Cache-Inhalt
  - Format: `üì¶ KOMPLETTER CACHE-INHALT:`
  - F√ºr jeden Eintrag: Session-ID, User-Text, Timestamp, Mode, URLs aller Quellen
  - Beispiel-Output:
    ```
    Session: 71ccc280-861a-41c2-88e2-1b96657f2d33
      User-Text: Wie wird das Wetter morgen in Niestetal, Hessen?
      Timestamp: 1761348296.2415316
      Mode: deep
      Quellen (3):
        1. https://www.wetter.com/...
        2. https://www.wetterdienst.de/...
        3. https://wetter.tv/...
    ```

- **Cache-Metadata Logging** in `lib/agent_core.py` (Zeilen 1312-1315):
  - Zeigt exakten Inhalt des Cache-Metadata wenn verf√ºgbar
  - Hilft bei Diagnose von Cache-basierten Entscheidungen

#### URL-Rating Parse-Fehler Logging
- **Erweiterte Fehlerausgabe** in `lib/agent_core.py` (Zeilen 742-744):
  - Zeigt problematische Zeile bei Parse-Fehlern
  - Format: `‚ö†Ô∏è Parse-Fehler f√ºr URL 3: list index out of range`
  - Zeigt erwartetes Format: `[NUM]. Score: [0-10] - Reasoning: [TEXT]`
  - Hilft bei Diagnose von LLM-Format-Fehlern (aktuell ~15% bei phi3:mini/qwen2.5:3b)

#### Haupt-LLM Message Logging
- **Komplettes Message-Array Logging** in `lib/agent_core.py` (Zeilen 1132-1145)
  - Zeigt alle Messages die an Haupt-LLM (z.B. qwen3:8b) √ºbergeben werden
  - Inklusive System-Prompt Preview (erste 500 Zeichen)
  - Zeigt Gesamt-Token-Count und Context-Window-Gr√∂√üe

#### UI-Verbesserungen
- **Debug-Console Gr√∂√üe erh√∂ht**: 21 ‚Üí 25 Zeilen (vertikal)
- **Auto-Refresh Toggle** in `aifred_intelligence.py` (Zeilen 647-659, 743-754):
  - Checkbox zum Ein/Ausschalten der automatischen Console-Aktualisierung
  - Bei Deaktivierung: Timer stoppt komplett (kein Scroll-Jump mehr)
  - Erlaubt ruhiges Scrollen und Analysieren w√§hrend laufender Requests
- **Sofortige Chat-Anzeige** in `aifred_intelligence.py` (Zeilen 1247-1251):
  - Chatbot-Widget wird sofort nach AI-Antwort aktualisiert
  - User sieht Antwort BEVOR Cache-Metadata und TTS laufen
  - Verbesserte Responsiveness der UI

#### Intent-Detection Verbesserungen
- **Verbessertes Logging** in `lib/agent_core.py` (Zeilen 492, 516, 575, 695):
  - Zeigt jetzt explizit welches Modell verwendet wird
  - Format: `üéØ Cache-Followup Intent-Detection mit phi3:mini: ...`
  - Format: `‚úÖ Cache-Followup Intent (phi3:mini): FAKTISCH`
  - Format: `üì® MESSAGES an qwen3:1.7b (Query-Opt):` (vorher: hardcodiert "phi3:mini")
  - Format: `üì® MESSAGES an qwen3:1.7b (URL-Rating):` (vorher: hardcodiert "phi3:mini")
- **Verbesserter Prompt** in `prompts/followup_intent_detection.txt`:
  - "Empfehlungen geben" explizit als KREATIV definiert
  - Neue Beispiele: "Kannst du mir Empfehlungen geben?" ‚Üí KREATIV
  - "Was k√∂nnte ich... unternehmen?" ‚Üí KREATIV
  - **Test-Ergebnis**: qwen2.5:3b erkennt Empfehlungs-Fragen korrekt als KREATIV

#### URL-Rating Verbesserungen
- **Generische lokale Relevanz** in `prompts/url_rating.txt`:
  - Neue Kategorie "LOKALE RELEVANZ" (+0 bis +2 Punkte)
  - Erkennt automatisch Orts-Fragen (z.B. "Berlin", "M√ºnchen", "Kassel")
  - Bevorzugt URLs mit Ortsnamen (kassel.de, vhs-kassel.de, nordhessen.de) ‚Üí +2
  - Bestraft allgemeine Blogs ohne Ortsbezug bei Orts-Fragen ‚Üí -2
  - Funktioniert f√ºr JEDE Stadt, nicht hardcodiert
- **Verst√§rkte Anti-Forum/Social-Media Regel**:
  - Foren (seniorennet.be, random-forum.com) ‚Üí -3 Punkte
  - Social Media (Pinterest, Instagram) ‚Üí -2 Punkte
- **Konkrete Beispiele hinzugef√ºgt**:
  - "Aktivit√§ten Kassel" + kassel.de ‚Üí Score 10
  - "Aktivit√§ten Kassel" + vhs-kassel.de ‚Üí Score 10
  - "Aktivit√§ten Kassel" + seniorennet.be/forum ‚Üí Score 2

#### Automatisches URL-Fallback f√ºr fehlgeschlagenes Scraping
- **Intelligentes Fallback-System** in `lib/agent_core.py` (Zeilen 1020-1133):
  - **Deep-Modus**: Startet mit 7 URLs statt 5 (Quick-Modus: unver√§ndert 3)
  - **Automatische Nachscraping**: Wenn URLs fehlschlagen (404, Timeout, Bot-Protection, PDF-Fehler):
    - System erkennt zu wenige erfolgreiche Quellen (< 5)
    - Scraped automatisch n√§chste URLs aus der Rating-Liste
    - Ziel: Immer 5 erfolgreiche Quellen (statt nur 3/5 wie vorher)
  - **Intelligente Stopbedingung**: H√∂rt auf sobald Ziel erreicht (spart Zeit)
  - **Beispiel**: VHS-PDF + TripAdvisor scheitern ‚Üí System scraped kassel.de + nordhessen.de nach
  - **Logging**: Zeigt Fallback-Fortschritt: `üîÑ Fallback: 3/5 erfolgreich ‚Üí Scrape 2 weitere URLs`
- **Performance-Optimierung**: Fallback-URLs werden ebenfalls parallel gescraped
- **User-Request**: "wenn er Schwierigkeiten hat und geblockt wird, dass er dann einfach die n√§chsten in der Liste scrapet"

### üêõ Behoben

#### **KRITISCH: Cache-Lookup & Storage Bug**
- **Root Cause**: `if not _research_cache` behandelt leeres Dict `{}` als `None`
- **Problem**: Cache wurde NIEMALS gespeichert, da bei leerem Dict sofort `return` erfolgte
- **Fix in `lib/agent_core.py`**:
  - Zeile 74 (`get_cached_research`): `if not _research_cache` ‚Üí `if _research_cache is None`
  - Zeile 210 (`save_cached_research`): `if not _research_cache` ‚Üí `if _research_cache is None`
- **Impact**: Cache funktioniert jetzt korrekt - Request 1 speichert, Request 2 findet und nutzt Cache
- **Test-Ergebnis**: ‚úÖ Cache-Hit nach 98s f√ºr Follow-up-Frage (statt erneuter 98s Web-Scraping)

#### Decision-LLM ignoriert lokale Aktivit√§ten-Fragen
- **Problem**: Fragen wie "Aktivit√§ten in Kassel?" wurden als `<search>no</search>` eingestuft
  - LLM dachte, es k√∂nnte aus Trainingsdaten antworten (generische Vorschl√§ge)
  - Resultat: Keine Web-Recherche ‚Üí Veraltete/ungenaue Informationen
- **Fix in `prompts/decision_making.txt`**:
  - Neue Regel: "Lokale Aktivit√§ten/Empfehlungen/Events ‚Üí <search>yes</search>"
  - Neue Regel: "Restaurants/Gesch√§fte/Orte in Stadt ‚Üí <search>yes</search>"
  - Neue Beispiele:
    - "Aktivit√§ten in Kassel?" ‚Üí <search>yes</search>
    - "Was kann ich in M√ºnchen machen?" ‚Üí <search>yes</search>
    - "VHS-Kurse in Kassel?" ‚Üí <search>yes</search>
- **User-Feedback**: "Erst die explizite Nachfrage, warum hast du nicht im Internet recherchiert, hat es dann getriggert."
- **Resultat**: Lokale Fragen triggern jetzt korrekt Web-Recherche f√ºr aktuelle, lokale Infos

#### URLs in Inline-Zitaten entfernt
- **Prompt-Update** in `prompts/system_rag.txt` (Zeilen 44-48):
  - ‚úÖ RICHTIG: "Quelle 1 berichtet, dass das Wetter morgen regnerisch wird..."
  - ‚ùå FALSCH: "Quelle 1 (https://www.wetter.com/...) berichtet..."
  - URLs NUR in Quellen-Liste am Ende, NIEMALS im Flie√ütext
- **Resultat**: Sauberere, lesbarere AI-Antworten ohne URL-Clutter

#### Context Limit Detection
- **Priorisierung korrigiert** in `lib/agent_core.py` (Zeilen 273-285):
  - `original_context_length` wird jetzt VOR `.context_length` gepr√ºft
  - Verhindert falsche Extended-Context-Werte f√ºr Modelle mit RoPE-Scaling
  - Beispiel: phi3:mini zeigt jetzt korrekt 4096 statt 131072 Tokens

#### Context Limit Warning Bug
- **is_automatik_llm Parameter korrigiert** in `lib/agent_core.py` (Zeile 1137):
  - Haupt-LLM (qwen3:8b) nutzt jetzt korrekt `is_automatik_llm=False`
  - Verhindert falsche Warnung: "5687 Tokens > 4096 Limit" ‚Üí jetzt korrekt "5687 < 40960"

#### Sprachliche Mehrdeutigkeit in Decision Prompt
- **"Tag" ‚Üí "XML-Markierung"** in `prompts/decision_making.txt`:
  - Zeile 5: "ANTWORTE NUR MIT EINEM TAG" ‚Üí "ANTWORTE NUR MIT EINER DIESER XML-MARKIERUNGEN"
  - Zeile 27: "Antworte NUR mit dem Tag!" ‚Üí "Antworte NUR mit der XML-Markierung (nichts anderes)!"
  - Verhindert Verwechslung mit deutschem Wort "Tag" (= day)
  - **Resultat**: qwen2.5:3b w√§hlt jetzt korrekt `<search>yes</search>` f√ºr Wetter-Fragen

#### URL-Rating Format Enforcement
- **Verst√§rkter Prompt** in `prompts/url_rating.txt` (Zeilen 37-45):
  - ‚ö†Ô∏è ABSOLUT KRITISCH Sektion hinzugef√ºgt
  - JEDE Zeile MUSS EXAKT beginnen: `[NUM]. Score: [0-10] - Reasoning: [TEXT]`
  - KEINE zus√§tzlichen Erkl√§rungen, Kommentare oder Abweichungen
  - Ziel: Reduktion der Parse-Fehlerrate von ~15% (3 von 20 URLs)

#### External Library Logging Spam
- **Logging-Level auf WARNING gesetzt** in `lib/agent_tools.py` (Zeilen 30-34):
  - Trafilatura "discarding element" Messages unterdr√ºckt
  - Playwright, urllib3, requests Debug-Output deaktiviert
  - Journal Control bleibt sauber

### ‚ö° Optimiert

#### Scraping Timeouts reduziert
- **Trafilatura Timeout**: 15s ‚Üí 10s (`lib/agent_tools.py` Zeile 645)
- **Playwright Timeout**: 15000ms ‚Üí 10000ms (`lib/agent_tools.py` Zeile 773)
- **Thread Timeout**: 20s ‚Üí 10s (`lib/agent_core.py` Zeile 1036)
- **Intelligente Strategie**: Download-Fail = Max 10s (kein Playwright), JS-Heavy = Max 20s (Trafilatura + Playwright)

### üîß Ge√§ndert

#### Logging Helper Functions
- **Neue Helper-Funktionen** in `lib/logging_utils.py` (Zeilen 93-143):
  - `debug_print_prompt(prompt_type, prompt, model_name)`: Standardisiertes Prompt-Logging
  - `debug_print_messages(messages, model_name, context)`: Standardisiertes Messages-Logging
  - Reduziert Code-Duplikation in agent_core.py
  - Zeigt Message-Arrays, Token-Counts, Ollama-Parameter

#### Import Consolidation
- **aifred_intelligence.py**: Alle `agent_core` Imports in einen Block zusammengefasst (Zeilen 25-32)
- Entfernt: Unused `import sys` aus agent_core.py

#### Architektur-Vereinfachung: Context Limits
- **Dictionary entfernt**, ersetzt durch 2 globale Variablen in `lib/agent_core.py`:
  - `_haupt_llm_context_limit = 4096` (Fallback)
  - `_automatik_llm_context_limit = 4096` (Fallback)
- **Setter-Funktionen**: `set_haupt_llm_context_limit()`, `set_automatik_llm_context_limit()`
- **Call-Sites updated**: `is_automatik_llm=True/False` statt Modell-Namen √ºbergeben

#### Performance-Logging zentralisiert
- **ollama_wrapper.py** loggt jetzt automatisch alle `ollama.chat()` Aufrufe
- `_log_ollama_performance()` extrahiert Metriken und berechnet t/s
- Reduziert Code-Duplikation in agent_core.py

#### Journal Control Ausgabe deaktiviert
- **stdout logging auskommentiert** in `lib/logging_utils.py` (Zeile 58)
- Alle Logs gehen nur noch in Debug-Datei (kein doppelt gemoppelt)
- Spart Zeit und vermeidet journald Rate-Limiting

### üß™ Getestet

#### Decision-Making Performance Vergleich
**Test:** "Wie wird das Wetter morgen in Niestetal, Hessen?"

| Modell | Entscheidungszeit | t/s Gen | Ergebnis | Gesamtzeit |
|--------|------------------|---------|----------|-----------|
| **qwen2.5:3b** | 2.8s | 113 t/s | `<search>yes</search>` ‚úÖ | 59.5s |
| **phi3:mini** | 2.5s | 111 t/s | `<search>yes</search>` ‚úÖ | 96.2s |

**Fazit:**
- phi3:mini 0.3s schneller bei Entscheidung (11% Zeitersparnis)
- qwen2.5:3b 36.7s schneller gesamt (bessere URL-Rating Performance)
- Beide Modelle w√§hlen korrekt f√ºr Wetter-Fragen

#### Intelligent Scraping Test
**AccuWeather Blocking:**
- Trafilatura Download failed ‚Üí Playwright SKIP ‚úÖ
- Zeit: Sofortiger Skip statt 43s Timeout
- Log-Message: "‚ö†Ô∏è trafilatura Download failed ‚Üí SKIP Playwright (Site blockiert/down)"

**JS-Heavy Sites (wetter.com, proplanta.de):**
- Trafilatura: 27-577 W√∂rter
- Playwright Retry: 265-1526 W√∂rter ‚úÖ
- Zeit: ~4-6s pro Site (Trafilatura + Playwright)

### üìù Dokumentation

- **CHANGELOG.md** erstellt (diese Datei)
- Debug-Logging System dokumentiert
- Performance-Metriken f√ºr Decision-Making dokumentiert

---

## Fr√ºhere Versionen

Siehe Git-History f√ºr detaillierte √Ñnderungen vor diesem Datum.
