# ğŸ© AIfred Intelligence

**AI at your service** â€¢ *PersÃ¶nlicher Voice Assistant mit Multi-Model Support und Web-Recherche*

---

## ğŸ“– Die Geschichte hinter dem Namen

**AIfred Intelligence** ist mehr als nur ein cleverer Wortspiel (A.I. = AIfred Intelligence = Artificial Intelligence).

Der Name ehrt **drei Generationen**:

1. **Alfred** - Mein GroÃŸvater
2. **Wolfgang Alfred** - Mein Vater
3. **Ich** - (werde selbst GroÃŸvater meines Sohnes sein)

Wie der legendÃ¤re Butler Alfred aus Batman, der immer loyal, intelligent und hilfsbereit an der Seite steht, soll auch dieser AI-Assistent ein zuverlÃ¤ssiger Begleiter sein.

*"AIfred Intelligence - AI at your service"* ğŸ©

---

## âœ¨ Features

### ğŸ™ï¸ **Multi-Modal Voice Interface**
- **Spracheingabe** mit Whisper (faster-whisper)
- **Sprachausgabe** mit Edge TTS (Cloud) oder Piper TTS (lokal)
- **Text-Alternative** fÃ¼r schnelle Eingaben
- **STT-Korrektur**: Optional Transkription vor dem Senden bearbeiten

### ğŸ¤– **Multi-Model AI Support (Ollama)**
- **qwen2.5:14b** - Beste RAG-Performance (100% Recherche, 0% Training)
- **qwen3:8b** - Balance zwischen Speed und QualitÃ¤t
- **command-r** - Enterprise RAG fÃ¼r lange Dokumente
- **mixtral:8x7b** - Mixture-of-Experts (47B params, 8 Experten)
- **llama3.1:8b** / **llama3.2:3b** - Schnelle Allzweck-Modelle
- **mistral** - Optimiert fÃ¼r Code und Instruktionen

### ğŸ” **Agentic Web Research (Multi-API)**
Intelligente 3-Stufen Web-Suche mit automatischem Fallback:

1. **Brave Search API** (Primary) - 2.000 Requests/Monat, privacy-focused
2. **Tavily AI** (Fallback) - 1.000 Requests/Monat, RAG-optimiert
3. **SearXNG** (Last Resort) - Unlimited, self-hosted

**4 Research-Modi:**
- ğŸ§  **Eigenes Wissen** - Schnell, offline, nur AI-Training
- âš¡ **Web-Suche Schnell** - 1 beste Quelle gescraped
- ğŸ” **Web-Suche AusfÃ¼hrlich** - 3 beste Quellen gescraped
- ğŸ¤– **Automatik** - KI entscheidet intelligent, ob Web-Recherche nÃ¶tig ist

**AI-basierte URL-Bewertung:**
- AI bewertet alle gefundenen URLs (Score 1-10)
- Nur URLs mit Score â‰¥ 6 werden gescraped
- Intelligente Auswahl der relevantesten Quellen

### ğŸ’­ **Denkprozess-Transparenz**
- `<think>` Tags werden automatisch erkannt
- Als **Collapsible Accordion** im Chat anzeigbar (weiÃŸ auf anthrazit)
- Kompakte Darstellung ohne Ã¼berflÃ¼ssige Leerzeilen
- **Nicht in TTS** - Denkprozess wird nur angezeigt, nicht vorgelesen
- Zeigt AI's Reasoning-Prozess (perfekt fÃ¼r Debugging und Lernen!)

### ğŸ“Š **Chat History mit Context**
- VollstÃ¤ndiger Konversationsverlauf
- Timing-Informationen (STT, Agent, Inferenz, TTS)
- **Model-Wechsel Separator**: Zeigt an, wann KI-Modell gewechselt wurde
- Quellen-URLs immer sichtbar

### âš™ï¸ **Umfangreiche Einstellungen**
- **AI-Model Wechsel** on-the-fly
- **Stimmen-Auswahl** (Edge TTS: 10+ deutsche Stimmen)
- **TTS-Engine Toggle** (Edge Cloud vs. Piper Lokal)
- **TTS-Optimierung**: Emojis und `<think>` Tags werden automatisch aus Sprachausgabe entfernt
- **Geschwindigkeit** fÃ¼r TTS-Generierung
- **Whisper-Model Wahl** (tiny â†’ large-v3)
- **Research-Mode** direkt bei Texteingabe
- **Input-Sperre**: Alle Eingaben deaktiviert wÃ¤hrend Verarbeitung lÃ¤uft

---

## ğŸš€ Installation

### 1. **Voraussetzungen**
```bash
# Python 3.10+
python3 --version

# Ollama installieren
curl -fsSL https://ollama.com/install.sh | sh

# AI-Modelle herunterladen (z.B.)
ollama pull qwen2.5:14b
ollama pull llama3.2:3b
```

### 2. **Repository klonen**
```bash
git clone https://github.com/Peuqui/AIfred-Intelligence.git
cd AIfred-Intelligence
```

### 3. **Virtual Environment & Dependencies**
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 4. **API Keys konfigurieren (Optional)**
```bash
# Kopiere .env.example zu .env
cp .env.example .env

# Editiere .env und fÃ¼ge API Keys ein:
# - Brave Search API: https://brave.com/search/api/
# - Tavily AI: https://tavily.com/
nano .env
```

**Hinweis:** Ohne API Keys lÃ¤uft automatisch **SearXNG** als Fallback!

### 5. **SearXNG starten (Self-Hosted Search)**
```bash
cd docker/searxng
docker compose up -d
```

SearXNG lÃ¤uft nun auf `http://localhost:8888`

### 6. **Voice Assistant starten**
```bash
cd /home/mp/Projekte/AIfred-Intelligence
source venv/bin/activate
python mobile_voice_assistant.py
```

Ã–ffne Browser: `https://localhost:7860` (oder LAN-IP fÃ¼r mobile GerÃ¤te)

---

## ğŸ“ Projekt-Struktur

```
AIfred-Intelligence/
â”œâ”€â”€ mobile_voice_assistant.py    # Haupt-App (Gradio UI + Logic)
â”œâ”€â”€ agent_tools.py                # Agent-System (Multi-API Search, Scraping)
â”œâ”€â”€ requirements.txt              # Python Dependencies
â”œâ”€â”€ .env.example                  # API Keys Template
â”œâ”€â”€ .env                          # Deine API Keys (nicht in Git!)
â”œâ”€â”€ settings.json                 # User Settings (Auto-generiert)
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ searxng/
â”‚       â”œâ”€â”€ compose.yml           # SearXNG Docker Setup
â”‚       â””â”€â”€ settings.yml          # SearXNG Config (German)
â””â”€â”€ docs/
    â”œâ”€â”€ LLM_COMPARISON.md         # Detaillierte Model-Vergleiche
    â””â”€â”€ architecture-agentic-features.md
```

---

## ğŸ¯ Nutzung

### Typischer Workflow:

1. **Aufnehmen**: Klicke auf Mikrofon â†’ Sprich deine Frage â†’ Stopp
2. **Auto-Transkription**: Text wird automatisch nach Stopp transkribiert
3. **Optional**: Mit "âœï¸ Text nach Transkription zeigen" kannst du vorher korrigieren
4. **AI antwortet**: Automatisch mit Sprachausgabe (falls aktiviert)
5. **Warten**: Alle Eingaben sind gesperrt bis AI komplett fertig ist (inkl. TTS)

**Wichtig**: WÃ¤hrend die KI arbeitet, sind alle EingabemÃ¶glichkeiten deaktiviert. So vermeidest du versehentliche Mehrfach-Anfragen in der Queue!

### Research-Modi wÃ¤hlen:

- **Schnelle Fragen** (z.B. "Was ist Photosynthese?"): ğŸ§  **Eigenes Wissen**
- **Aktuelle News** (z.B. "Neueste Trump News"): âš¡ **Web-Suche Schnell**
- **Tiefe Recherche** (z.B. "Vergleiche React vs. Vue 2024"): ğŸ” **Web-Suche AusfÃ¼hrlich**
- **Automatische Entscheidung**: ğŸ¤– **Automatik** - KI analysiert die Frage und entscheidet selbst, ob Web-Recherche benÃ¶tigt wird

### AI-Model wechseln:

- **Schnell & Allgemein**: llama3.2:3b, llama3.1:8b
- **Web-Recherche**: qwen2.5:14b (beste RAG-Performance!)
- **Code schreiben**: mistral, mixtral:8x7b
- **Komplexe Tasks**: command-r, mixtral:8x7b

---

## ğŸ› ï¸ Systemd Service (Optional)

FÃ¼r Autostart beim Booten:

```bash
sudo systemctl enable voice-assistant.service
sudo systemctl start voice-assistant.service
sudo systemctl status voice-assistant.service
```

Service-Datei: `/etc/systemd/system/voice-assistant.service`

---

## ğŸ”§ Technologie-Stack

- **Frontend**: Gradio 4.x (Python Web UI Framework)
- **AI Models**: Ollama (llama3, qwen, mistral, mixtral, command-r)
- **Speech-to-Text**: faster-whisper (OpenAI Whisper optimiert)
- **Text-to-Speech**:
  - Edge TTS (Microsoft Cloud, beste QualitÃ¤t)
  - Piper TTS (lokal, Thorsten Stimme)
- **Web Search APIs**:
  - Brave Search API (Primary)
  - Tavily AI (Fallback)
  - SearXNG (Self-hosted, Last Resort)
- **Web Scraping**: BeautifulSoup4, Requests
- **Container**: Docker (SearXNG)

---

## ğŸ“Š Performance

### Typische Antwortzeiten:

**Eigenes Wissen (kein Agent):**
- STT: ~1s (base model)
- AI Inferenz: ~5-10s (llama3.2:3b) bis ~20-30s (qwen2.5:14b)
- TTS: ~2-3s (Edge TTS)
- **Total**: ~10-40s

**Web-Recherche Schnell (1 Quelle):**
- STT: ~1s
- Agent: ~15-30s (Search + Scraping + URL-Rating)
- AI Inferenz: ~20-40s (mit Context)
- TTS: ~2-3s
- **Total**: ~40-75s

**Web-Recherche AusfÃ¼hrlich (3 Quellen):**
- STT: ~1s
- Agent: ~60-120s (3x Scraping + Rating)
- AI Inferenz: ~30-60s (mit groÃŸem Context)
- TTS: ~2-3s
- **Total**: ~95-185s

---

## ğŸ› Bekannte EinschrÃ¤nkungen

- **Model-Separator** erscheint nur bei tatsÃ¤chlichem Model-Wechsel mit History
- **llama2:13b** hat nur ~78% RAG-AdhÃ¤renz (mischt Training Data)
- **llama3.2:3b** ignoriert RAG fast komplett (nicht fÃ¼r Web-Recherche!)

---

## ğŸ¤ Beitragen

Falls du Verbesserungen hast:
1. Fork das Repository
2. Erstelle einen Feature Branch
3. Commit deine Ã„nderungen
4. Ã–ffne einen Pull Request

---

## ğŸ“œ Lizenz

MIT License - siehe [LICENSE](LICENSE) Datei.

---

## ğŸ™ Danksagungen

- **Meta** fÃ¼r Llama Models
- **Alibaba Cloud** fÃ¼r Qwen Models
- **Mistral AI** fÃ¼r Mistral & Mixtral
- **OpenAI** fÃ¼r Whisper
- **Microsoft** fÃ¼r Edge TTS
- **SearXNG Community** fÃ¼r Privacy-Friendly Meta-Search
- **Thorsten MÃ¼ller** fÃ¼r deutsche Piper TTS Stimme

---

**AIfred Intelligence** - *AI at your service* ğŸ©

Benannt nach **Alfred** (GroÃŸvater) und **Wolfgang Alfred** (Vater)
