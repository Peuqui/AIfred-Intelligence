# LLM Modell-Vergleich - AIfred Intelligence

**Letzte Aktualisierung:** 2025-10-15 (Finale Benchmark-Ergebnisse)

---

## ğŸ§ª AKTUELLE BENCHMARK-ERGEBNISSE (2025-10-15)

**Methode:** Automatisierter Benchmark mit sauberem RAM, korrektem Thinking-Mode Parser, manuelle Auswertung

### Test-Szenarien:
1. **Trump/Hamas Test**: Komplexe News-Frage, erfordert Web-Recherche (erwartet: `yes`)
2. **Guten Morgen Test**: Einfache BegrÃ¼ÃŸung, keine Web-Recherche nÃ¶tig (erwartet: `no`)
3. **Wetter Test**: "Wetter morgen in Berlin" - MUSS Web-Recherche auslÃ¶sen (erwartet: `yes`)
4. **Geschwindigkeitstest**: Einfache Aufgabe zur Speed-Messung

### ğŸ“Š Ergebnisse-Ãœbersicht

| Modell | Test 1 (Trump/Hamas) | Test 2 (Guten Morgen) | Test 3 (Wetter) | Speed Test | **Status** |
|--------|----------------------|-----------------------|-----------------|------------|------------|
| **qwen3:1.7b** | âœ… yes (31.1s) | âœ… no (5.0s) | âœ… yes (6.3s) | 4.4s | **âœ… ALLE BESTANDEN** |
| **qwen3:8b** | âœ… yes (72.4s) | âœ… no (19.0s) | âœ… yes (13.3s) | 22.3s | **âœ… ALLE BESTANDEN** |
| **qwen2.5:32b** | âœ… yes (88.4s) | âœ… no (13.9s) | âœ… yes (14.4s) | 6.4s | **âœ… ALLE BESTANDEN** |
| qwen3:0.6b | âœ… yes (4.7s) | âœ… no (2.3s) | âŒ no (2.2s) | 2.0s | âŒ Versagt bei Wetter |
| qwen3:4b | âŒ no (315.0s) | âœ… no (40.6s) | âœ… yes (54.5s) | 68.4s | âŒ Versagt bei Trump/Hamas |
| llama3.2:3b | âŒ no (10.3s) | âœ… no (1.4s) | âŒ no (1.4s) | 1.1s | âŒ Versagt bei 2 Tests |

**Detaillierte Ergebnisse:** [BENCHMARK_RESULTS_FINAL.md](../BENCHMARK_RESULTS_FINAL.md)

---

## ğŸ† EMPFEHLUNGEN FÃœR AIFRED INTELLIGENCE

### â­â­â­â­â­ PRIMÃ„R-EMPFEHLUNG: qwen3:1.7b

**Warum?**
- âœ… Alle Tests bestanden (einziges kleines Modell!)
- âš¡ Schnellste Entscheidung bei voller Korrektheit (31.1s)
- ğŸ’¾ Sehr klein: 1.7B Parameter â‰ˆ 2 GB RAM
- ğŸ¯ Erkennt alle kritischen Trigger (News, Wetter, etc.)

**Einsatzgebiet:**
- **Automatik-Entscheidung**: Soll Web-Recherche durchgefÃ¼hrt werden?
- **Schnelle Anfragen**: Wenn Speed wichtiger ist als perfekte QualitÃ¤t

**Hardware:**
- RAM-Bedarf: ~2-3 GB
- CPU-Last: Moderat
- Inference: ~31s fÃ¼r komplexe Entscheidungen, ~5s fÃ¼r einfache

---

### â­â­â­â­ SEKUNDÃ„R-EMPFEHLUNG: qwen3:8b

**Warum?**
- âœ… Alle Tests bestanden
- ğŸ§  Bessere Reasoning-QualitÃ¤t als qwen3:1.7b
- ğŸ“Š Moderate Geschwindigkeit (72.4s fÃ¼r Trump/Hamas)
- ğŸ’ª Robuster bei komplexen Fragen

**Einsatzgebiet:**
- **Haupt-LLM**: Finale Antwortgenerierung nach erfolgreicher Web-Recherche
- **Komplexe Aufgaben**: Wenn QualitÃ¤t wichtiger ist als Geschwindigkeit

**Hardware:**
- RAM-Bedarf: ~8 GB
- CPU-Last: HÃ¶her als qwen3:1.7b
- Inference: ~72s fÃ¼r komplexe Aufgaben, ~19s fÃ¼r einfache

---

### â­â­â­ OPTIONAL: qwen2.5:32b (nur wenn viel RAM)

**Warum?**
- âœ… Alle Tests bestanden
- ğŸ¯ HÃ¶chste QualitÃ¤t
- âš¡ Kein Thinking Mode (direkte Antworten, spart Tokens)

**ABER:**
- âš ï¸ Sehr groÃŸ: 32B Parameter â‰ˆ 21 GB RAM!
- âš ï¸ Langsam: 88.4s fÃ¼r Trump/Hamas
- âš ï¸ Nicht geeignet fÃ¼r Automatik-Entscheidung

**Einsatzgebiet:**
- **Fallback**: Nur wenn genug RAM verfÃ¼gbar
- **Premium-Antworten**: Wenn beste QualitÃ¤t benÃ¶tigt wird

**Hardware:**
- RAM-Bedarf: ~21-24 GB (!)
- CPU-Last: Sehr hoch
- Inference: ~88s fÃ¼r komplexe Aufgaben

---

## âŒ NICHT EMPFOHLEN

### llama3.2:3b
- **Problem:** Versagt bei Trump/Hamas (News) UND Wetter
- **Grund:** Versteht kontextuelle Trigger nicht zuverlÃ¤ssig
- **Fazit:** Trotz hoher Geschwindigkeit (1.1s) nicht zuverlÃ¤ssig genug

### qwen3:0.6b
- **Problem:** Versagt bei Wetter-Erkennung
- **Grund:** Zu klein (0.6B) fÃ¼r komplexe Entscheidungslogik
- **Fazit:** Schnell (4.7s), aber unzuverlÃ¤ssig

### qwen3:4b
- **Problem:** Versagt bei Trump/Hamas trotz 315s (!) Thinking-Zeit
- **Grund:** Extrem langsam UND trotzdem fehleranfÃ¤llig
- **Fazit:** Schlechtestes Preis/Leistungs-VerhÃ¤ltnis aller Modelle

---

## ğŸ“Š Technische Ãœbersichtstabelle

| Modell | GrÃ¶ÃŸe | Automatik-Entscheidung | QualitÃ¤t | Speed | RAM | Status |
|--------|-------|------------------------|----------|-------|-----|--------|
| **qwen3:1.7b** | 2 GB | âœ… 31.1s | â­â­â­â­ | Schnell | ~3 GB | âœ… **EMPFOHLEN** |
| **qwen3:8b** | 8 GB | âœ… 72.4s | â­â­â­â­â­ | Mittel | ~8 GB | âœ… **EMPFOHLEN** |
| **qwen2.5:32b** | 21 GB | âœ… 88.4s | â­â­â­â­â­ | Langsam | ~22 GB | âš ï¸ Optional |
| qwen3:0.6b | 1 GB | âŒ Versagt | â­â­ | Sehr schnell | ~2 GB | âŒ |
| qwen3:4b | 4 GB | âŒ Versagt | â­ | Sehr langsam | ~5 GB | âŒ |
| llama3.2:3b | 2 GB | âŒ Versagt | â­â­ | Sehr schnell | ~3 GB | âŒ |

**Legende:**
- **Automatik-Entscheidung:** Zeit fÃ¼r Trump/Hamas-Test (komplexe Entscheidung)
- **QualitÃ¤t:** Reasoning-QualitÃ¤t und ZuverlÃ¤ssigkeit
- **Speed:** Relative Geschwindigkeit
- **RAM:** Speicherbedarf wÃ¤hrend Inferenz

---

## ğŸ¯ Implementierungs-Empfehlung

### âœ… **IMPLEMENTIERT in AIfred Intelligence (2025-10-15)**

```python
# aifred_intelligence.py
AUTOMATIK_MODEL = "qwen3:1.7b"  # Hardcoded fÃ¼r schnelle AI-Entscheidungen
```

**Hardcoded fÃ¼r Automatik-Tasks:**
- âœ… **Automatik-Entscheidung**: Web-Recherche JA/NEIN? â†’ `qwen3:1.7b`
- âœ… **Query-Optimierung**: Keyword-Extraktion â†’ `qwen3:1.7b`
- âœ… **URL-Bewertung**: 15 URLs filtern (7s/URL) â†’ `qwen3:1.7b`

**User-wÃ¤hlbar fÃ¼r Finale Antwort:**
- ğŸ”½ **Dropdown in UI**: User wÃ¤hlt zwischen qwen3:1.7b, qwen3:8b, qwen2.5:32b
- ğŸ¯ **Empfohlen**: qwen3:8b (Default)

---

### Ablauf im Automatik-Modus:

```
1. User stellt Frage
   â†“
2. qwen3:1.7b entscheidet (~5-30s): Web-Recherche nÃ¶tig?
   â†“ JA
3. qwen3:1.7b optimiert Query zu Keywords (~5-15s)
   â†“
4. Web-Recherche via SearXNG (15 URLs)
   â†“
5. qwen3:1.7b bewertet URLs (~105s fÃ¼r 15 URLs)
   â†“
6. Scrape Top 3-5 URLs
   â†“
7. USER-GEWÃ„HLTES MODELL generiert finale Antwort
   - qwen3:1.7b: ~30s (schnell)
   - qwen3:8b: ~1-2 Min (default, gute QualitÃ¤t)
   - qwen2.5:32b: ~3-5 Min (beste QualitÃ¤t)
```

**Vorteile dieser Strategie:**
- âš¡ **Schnelle Vorauswahl**: qwen3:1.7b filtert in ~2-3 Min (Entscheidung + Query + URL-Rating)
- ğŸ¯ **Flexible QualitÃ¤t**: User wÃ¤hlt Speed vs. Quality fÃ¼r finale Antwort
- ğŸ’¾ **Moderater RAM**: ~11 GB wenn qwen3:8b gewÃ¤hlt
- ğŸ” **Content-basierte URL-Bewertung**: Nicht Domain-basiert!

**Benchmark-Ergebnisse:**
- Automatik-Phase (qwen3:1.7b): ~2-3 Min total
  - Entscheidung: ~5-30s
  - Query-Opt: ~5-15s
  - URL-Rating: ~105s (15 URLs)
- Finale Antwort (User-wÃ¤hlbar):
  - qwen3:1.7b: +30s
  - qwen3:8b: +1-2 Min
  - qwen2.5:32b: +3-5 Min

---

## ğŸ”¬ Benchmark-Details

### Test 1: Trump/Hamas Entscheidung (Komplex)

**Frage:** "PrÃ¤sident Trump hat mit der Hamas und PrÃ¤sident Netanyahu ein Friedensabkommen geschlossen, welches von PrÃ¤sident Biden bereits vor Jahren vorbereitet war. Bitte recherchiere die entsprechenden Dokumente von PrÃ¤sident Biden."

**Trigger-WÃ¶rter:** Aktuelle News, Recherche, Dokumente, spezifische Events

| Modell | Antwort | Korrekt? | Zeit | Bemerkung |
|--------|---------|----------|------|-----------|
| qwen3:1.7b | `<search>yes</search>` | âœ… | 31.1s | Gute Analyse im Thinking Mode |
| qwen3:8b | `<search>yes</search>` | âœ… | 72.4s | Klare, korrekte Analyse |
| qwen2.5:32b | `<search>yes</search>` | âœ… | 88.4s | Direkte Antwort, kein Thinking |
| qwen3:0.6b | `<search>yes</search>` | âœ… | 4.7s | Korrekt, aber versagt bei Wetter |
| qwen3:4b | `EIGENES WISSEN REICHT` | âŒ | 315.0s | 300+ Zeilen Thinking, falsch! |
| llama3.2:3b | `<search>no</search>` | âŒ | 10.3s | Versteht News-Trigger nicht |

### Test 2: Einfache BegrÃ¼ÃŸung

**Frage:** "Guten Morgen"

**Erwartung:** Keine Web-Recherche nÃ¶tig

| Modell | Antwort | Korrekt? | Zeit |
|--------|---------|----------|------|
| qwen3:1.7b | `<search>no</search>` | âœ… | 5.0s |
| qwen3:8b | `<search>no</search>` | âœ… | 19.0s |
| qwen2.5:32b | `<search>no</search>` | âœ… | 13.9s |
| qwen3:0.6b | `<search>no</search>` | âœ… | 2.3s |
| qwen3:4b | `<search>no</search>` | âœ… | 40.6s |
| llama3.2:3b | `<search>no</search>` | âœ… | 1.4s |

**Erkenntnis:** Alle Modelle bestehen den einfachen Test âœ…

### Test 3: Wetter-Anfrage (KRITISCH!)

**Frage:** "Wie wird das Wetter morgen in Berlin?"

**Erwartung:** IMMER Web-Recherche (Wetter = Live-Daten)

| Modell | Antwort | Korrekt? | Zeit | Bemerkung |
|--------|---------|----------|------|-----------|
| qwen3:1.7b | `<search>yes</search>` | âœ… | 6.3s | **MindestgrÃ¶ÃŸe** fÃ¼r Wetter-Erkennung |
| qwen3:8b | `<search>yes</search>` | âœ… | 13.3s | ZuverlÃ¤ssig |
| qwen2.5:32b | `<search>yes</search>` | âœ… | 14.4s | ZuverlÃ¤ssig |
| qwen3:0.6b | `<search>no</search>` | âŒ | 2.2s | **Zu klein** fÃ¼r diese Entscheidung |
| qwen3:4b | `<search>yes</search>` | âœ… | 54.5s | Korrekt, aber sehr langsam |
| llama3.2:3b | `<search>no</search>` | âŒ | 1.4s | Versteht Wetter-Trigger nicht |

**Erkenntnis:** Nur Modelle mit â‰¥1.7B Parametern erkennen Wetter-Trigger korrekt!

### Test 4: Geschwindigkeitstest

**Frage:** "WÃ¼nsche mir einen guten Abend und hÃ¤nge drei Emojis dran."

| Modell | Zeit | Ranking | Bemerkung |
|--------|------|---------|-----------|
| llama3.2:3b | 1.1s | ğŸ¥‡ | Extrem schnell, aber unzuverlÃ¤ssig |
| qwen3:0.6b | 2.0s | ğŸ¥ˆ | Sehr schnell, aber Wetter-Fehler |
| qwen3:1.7b | 4.4s | ğŸ¥‰ | **Bester Kompromiss** |
| qwen2.5:32b | 6.4s | #4 | Schnell fÃ¼r GrÃ¶ÃŸe |
| qwen3:8b | 22.3s | #5 | Akzeptabel |
| qwen3:4b | 68.4s | #6 | Inakzeptabel langsam |

---

## ğŸ’¾ Hardware-Anforderungen (Mini-PC mit 32GB RAM)

### Minimum fÃ¼r qwen3:1.7b:
- RAM: 4 GB frei
- CPU: 4+ Cores
- Disk: 2 GB

### Empfohlen fÃ¼r qwen3:8b:
- RAM: 10 GB frei
- CPU: 6+ Cores
- Disk: 6 GB

### FÃ¼r qwen2.5:32b:
- RAM: 24+ GB frei (!)
- CPU: 8+ Cores
- Disk: 18 GB

### Aktueller Mini-PC Status:
- RAM: 32 GB total
- Status: âœ… Kann qwen3:1.7b + qwen3:8b gleichzeitig (~11 GB)
- Status: âš ï¸ qwen2.5:32b nur wenn nichts anderes lÃ¤uft

---

## ğŸš€ Performance-Messungen (Real)

**Basierend auf echten Benchmark-Messungen vom 2025-10-15:**

| Modell | Komplexe Aufgabe | Einfache Aufgabe | Durchschnitt |
|--------|------------------|------------------|--------------|
| qwen3:1.7b | 31.1s | 5.0s | ~18s |
| qwen3:8b | 72.4s | 19.0s | ~46s |
| qwen2.5:32b | 88.4s | 13.9s | ~51s |
| qwen3:0.6b | 4.7s | 2.3s | ~3.5s |
| qwen3:4b | 315.0s (!) | 40.6s | ~178s (!) |
| llama3.2:3b | 10.3s | 1.4s | ~6s |

**Hinweis:** Zeiten gemessen mit sauberem RAM, ohne Swap-Druck

---

## ğŸ“ Changelog

**2025-10-15:** Finale Benchmark-Ergebnisse mit korrektem Parser
- âœ… VollstÃ¤ndiger Benchmark aller 6 Modelle
- âœ… Sauberer RAM (kein Swap-VerfÃ¤lschung)
- âœ… Korrigierter Thinking-Mode Parser
- âœ… Manuelle Auswertung der Log-Dateien
- ğŸ¯ **Hauptempfehlung:** qwen3:1.7b fÃ¼r Automatik-Entscheidung
- ğŸ¯ **SekundÃ¤rempfehlung:** qwen3:8b fÃ¼r Hauptantworten
- âŒ **Nicht empfohlen:** llama3.2:3b, qwen3:0.6b, qwen3:4b

**2025-10-14:** Model-Downloads
- Downloaded: qwen3:0.6b, qwen3:1.7b, qwen3:4b
- Erste Tests mit fehlerhaftem Parser

**2025-10-13:** Initial comparison
- Downloaded: qwen3:8b, qwen2.5:32b
- Basis-Vergleich ohne Benchmarks

---

**Detaillierte Benchmark-Logs:** [benchmarks/logs_sequential/](../benchmarks/logs_sequential/)
**Finale QualitÃ¤ts-Auswertung:** [BENCHMARK_QUALITY_ANALYSIS.md](../benchmarks/BENCHMARK_QUALITY_ANALYSIS.md)
