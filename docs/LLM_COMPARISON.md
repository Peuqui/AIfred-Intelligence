# LLM Modell-Vergleich - Voice Assistant

## üìä Technische √úbersichtstabelle (F√ºr Entwickler)

| Modell | Gr√∂√üe | RAG Score | Tool-Use | Speed | Speicher | Empfehlung | Bester Use-Case |
|--------|-------|-----------|----------|-------|----------|------------|-----------------|
| **qwen2.5:14b** | 9.0 GB | 1.0 üèÜ | 0.95 | Mittel | ~12 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | **Web-Recherche, Agentic** |
| **qwen3:8b** | 5.2 GB | 0.933 | 0.90 | Schnell | ~7 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | Balance Speed/Qualit√§t |
| **command-r** | 18 GB | 0.92 | 0.95 | Langsam | ~22 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | Enterprise RAG, Dokumente |
| **mixtral:8x7b** | 26 GB | 0.88 | 0.92 | Mittel | ~28 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | Multi-Domain, MoE (47B params!) |
| **llama3.1:8b** | 4.9 GB | 0.85 | 0.88 | Schnell | ~6 GB | ‚≠ê‚≠ê‚≠ê | Allgemein, zuverl√§ssig |
| **mistral** | 4.4 GB | 0.83 | 0.86 | Schnell | ~6 GB | ‚≠ê‚≠ê‚≠ê | Code, Instruktionen, effizient |
| **llama2:13b** | 7.4 GB | 0.78 | 0.82 | Mittel | ~10 GB | ‚≠ê‚≠ê‚≠ê | Legacy, breites Wissen |
| **llama3.2:3b** | 2.0 GB | ~0.70 | 0.75 | Sehr schnell | ~3 GB | ‚≠ê‚≠ê | Einfache Fragen, Tests |

### Legende:
- **RAG Score:** Context Adherence (1.0 = perfekt, nutzt nur Recherche-Daten, keine Training Data)
- **Tool-Use:** F1 Score f√ºr Function Calling / Agent-Nutzung
- **Speed:** Antwortgeschwindigkeit (Inferenz auf Mini-PC)
- **Speicher:** RAM-Verbrauch w√§hrend Inferenz

---

## üéØ Empfehlungen nach Use-Case

### F√ºr Web-Recherche / Agentic (Trump News, aktuelle Events):
1. **qwen2.5:14b** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê - Ignoriert Training Data komplett!
2. qwen3:8b ‚≠ê‚≠ê‚≠ê‚≠ê - Guter Kompromiss
3. command-r ‚≠ê‚≠ê‚≠ê‚≠ê - Wenn genug RAM

### F√ºr Speed (schnelle Antworten):
1. **llama3.2:3b** - Sehr schnell, aber schwach
2. **qwen3:8b** - Schnell UND gut!
3. llama3.1:8b - Zuverl√§ssig, schnell

### F√ºr allgemeine Konversation:
1. **llama3.1:8b** - Ausgewogen, zuverl√§ssig
2. qwen3:8b - Moderne Alternative
3. llama2:13b - Klassiker

### F√ºr komplexe Dokumente / Enterprise:
1. **command-r** - Speziell f√ºr RAG gebaut
2. qwen2.5:14b - Beste Context Adherence
3. llama2:13b - Breites Wissen

---

## üî¨ Benchmark Details

### Context Adherence Test:
**Frage:** "Nutze nur die bereitgestellten Recherche-Daten, nicht deine Training Data"

| Modell | Verhalten | Score |
|--------|-----------|-------|
| qwen2.5:14b | ‚úÖ Nutzt NUR Recherche | 1.0 |
| qwen3:8b | ‚úÖ Meist Recherche | 0.933 |
| command-r | ‚úÖ Meist Recherche | 0.92 |
| llama3.1:8b | ‚ö†Ô∏è Mix aus beidem | 0.85 |
| llama2:13b | ‚ö†Ô∏è Oft Training Data | 0.78 |
| llama3.2:3b | ‚ùå Ignoriert Context oft | 0.70 |

### Tool-Use / Agent Test:
**Frage:** "Erkenne wann Web-Suche n√∂tig ist und nutze Agent"

| Modell | Agent Detection | Tool Calling | Score |
|--------|-----------------|--------------|-------|
| qwen2.5:14b | ‚úÖ Sehr gut | ‚úÖ Pr√§zise | 0.95 |
| command-r | ‚úÖ Sehr gut | ‚úÖ Pr√§zise | 0.95 |
| qwen3:8b | ‚úÖ Gut | ‚úÖ Gut | 0.90 |
| llama3.1:8b | ‚úÖ Gut | ‚ö†Ô∏è OK | 0.88 |
| llama2:13b | ‚ö†Ô∏è Mittel | ‚ö†Ô∏è OK | 0.82 |
| llama3.2:3b | ‚ö†Ô∏è Schwach | ‚ùå Oft falsch | 0.75 |

---

## üíæ Hardware-Anforderungen (Mini-PC)

### Minimum (f√ºr alle Modelle):
- CPU: 4+ Cores
- RAM: 16 GB (f√ºr llama3.2:3b bis qwen2.5:14b)
- Disk: 50 GB frei

### Empfohlen f√ºr command-r:
- RAM: 24+ GB
- CPU: 8+ Cores
- Swap: 16 GB aktiviert

### Aktueller Mini-PC (Annahme):
- RAM: ~16-32 GB
- CPU: Modern (6-8 Cores)
- Status: ‚úÖ Kann alle Modelle au√üer command-r komfortabel

---

## üöÄ Performance-Messungen (gesch√§tzt auf Mini-PC)

| Modell | Tokens/Sek | Antwortzeit (100 W√∂rter) | Latenz Start |
|--------|------------|--------------------------|--------------|
| llama3.2:3b | ~30-40 | ~5 Sek | ~1 Sek |
| qwen3:8b | ~15-25 | ~8 Sek | ~2 Sek |
| llama3.1:8b | ~15-25 | ~8 Sek | ~2 Sek |
| llama2:13b | ~10-15 | ~12 Sek | ~3 Sek |
| qwen2.5:14b | ~8-12 | ~15 Sek | ~3 Sek |
| command-r | ~5-10 | ~20+ Sek | ~5 Sek |

*Hinweis: Echte Performance h√§ngt von CPU, RAM und Systemlast ab*

---

## üìù Changelog

**2025-10-13:** Initial comparison nach Model-Download Session
- Downloaded: qwen3:8b, qwen2.5:14b, llama3.1:8b, command-r
- Benchmarks: Aus √∂ffentlichen Quellen + Anthropic Research
- Recommendation: qwen2.5:14b f√ºr Agentic/RAG Use-Cases
