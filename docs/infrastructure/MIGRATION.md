# üì¶ Migration & Portabilit√§t

Anleitung zum Portieren von AIfred Intelligence auf einen anderen Rechner.

---

## ‚úÖ Was ist portabel (automatisch)

Diese Komponenten funktionieren **ohne √Ñnderungen** auf jedem System:

### üîß Code & Konfiguration
- ‚úÖ **Python Code** - Alle `.py` Dateien und `lib/` Modul
- ‚úÖ **Pfade** - Verwendet `PROJECT_ROOT = Path(__file__).parent.parent.absolute()`
- ‚úÖ **Dependencies** - `requirements.txt` f√ºr pip install
- ‚úÖ **Settings** - `assistant_settings.json` (wird automatisch erstellt)

### üåê Externe Services (localhost)
- ‚úÖ **Ollama** - L√§uft auf `http://localhost:11434` (Standard-Port)
- ‚úÖ **SearXNG** - L√§uft auf `http://localhost:8888` (konfigurierbar)
- ‚úÖ **Gradio UI** - Bindet an `0.0.0.0:7860` (alle Interfaces)

---

## ‚öôÔ∏è Was muss angepasst werden

### 1. **SSL-Zertifikate** (Optional f√ºr HTTPS)

**Aktueller Pfad** (wird automatisch erkannt):
```python
# lib/config.py
SSL_KEYFILE = PROJECT_ROOT / "ssl" / "privkey.pem"
SSL_CERTFILE = PROJECT_ROOT / "ssl" / "fullchain.pem"
```

**Auf neuem System:**
- Entweder: Eigene Zertifikate in `ssl/` Verzeichnis legen
- Oder: Ohne SSL starten (HTTP statt HTTPS)

**Fallback**: Code pr√ºft automatisch, ob Zertifikate existieren:
```python
if SSL_KEYFILE.exists() and SSL_CERTFILE.exists():
    # HTTPS
else:
    # HTTP
```

### 2. **Piper TTS Model** (Optional f√ºr lokales TTS)

**Aktueller Pfad**:
```python
# lib/config.py
PIPER_MODEL_PATH = PROJECT_ROOT / "piper_models" / "de_DE-thorsten-medium.onnx"
```

**Auf neuem System:**
1. Piper Model herunterladen (falls lokal TTS gew√ºnscht)
2. In `piper_models/` Verzeichnis legen
3. **Fallback**: Ohne Piper l√§uft nur Edge TTS (Cloud)

### 3. **API Keys** (Optional f√ºr Brave/Tavily)

**`.env` Datei erstellen:**
```bash
cp .env.example .env
nano .env
```

**Inhalt**:
```env
BRAVE_API_KEY=your_brave_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
```

**Fallback**: Ohne API Keys l√§uft **SearXNG** als einzige Suchmaschine.

### 4. **Systemd Service** (Optional f√ºr Autostart)

**Service-Datei anpassen** (`/etc/systemd/system/aifred-intelligence.service`):

```ini
[Service]
User=<DEIN_USERNAME>                          # ‚Üê Anpassen!
WorkingDirectory=/pfad/zu/AIfred-Intelligence  # ‚Üê Anpassen!
ExecStart=/pfad/zu/venv/bin/python -u aifred_intelligence.py  # ‚Üê Anpassen!
Environment="PATH=/pfad/zu/venv/bin:/usr/local/bin:/usr/bin"  # ‚Üê Anpassen!
```

**Installation:**
```bash
sudo systemctl daemon-reload
sudo systemctl enable aifred-intelligence.service
sudo systemctl start aifred-intelligence.service
```

---

## üìã Migrations-Checkliste

### Schritt 1: Repository klonen
```bash
git clone https://github.com/Peuqui/AIfred-Intelligence.git
cd AIfred-Intelligence
```

### Schritt 2: Virtual Environment erstellen
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Schritt 3: Ollama installieren & Modelle pullen
```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama pull qwen3:1.7b   # F√ºr Automatik
ollama pull qwen3:8b     # F√ºr Hauptmodell (empfohlen)
ollama pull qwen3:32b    # Optional: Beste Qualit√§t
```

### Schritt 4: SearXNG starten (Docker)
```bash
cd docker/searxng
docker compose up -d
```

**Test**: √ñffne `http://localhost:8888` im Browser

### Schritt 5: SSL-Zertifikate (Optional)
```bash
# Entweder: Eigene Zertifikate in ssl/ legen
mkdir -p ssl
cp /pfad/zu/privkey.pem ssl/
cp /pfad/zu/fullchain.pem ssl/

# Oder: Ohne SSL starten (HTTP)
# ‚Üí Code erkennt automatisch fehlende Zertifikate
```

### Schritt 6: Piper TTS Model (Optional)
```bash
# Falls lokales TTS gew√ºnscht:
mkdir -p piper_models
cd piper_models
wget https://huggingface.co/rhasspy/piper-voices/resolve/main/de/de_DE/thorsten/medium/de_DE-thorsten-medium.onnx
```

### Schritt 7: API Keys konfigurieren (Optional)
```bash
cp .env.example .env
nano .env  # F√ºge API Keys ein
```

### Schritt 8: Anwendung starten
```bash
source venv/bin/activate
python aifred_intelligence.py
```

**√ñffne Browser**: `https://localhost:7860` (oder `http://...` ohne SSL)

---

## üîÑ Settings-Migration

**Settings werden automatisch migriert!**

Alte Settings (`settings.json`) werden beim ersten Start automatisch zu `assistant_settings.json` konvertiert:

```python
# lib/settings_manager.py
def load_settings():
    # Alte Settings laden
    if old_file.exists() and not new_file.exists():
        shutil.copy(old_file, new_file)
        # Migration erfolgreich
```

**Was wird migriert:**
- AI Model Auswahl
- Automatik Model
- Voice & TTS Settings
- Whisper Model
- Research Mode
- Alle User-Pr√§ferenzen

---

## üõ†Ô∏è Troubleshooting

### Problem: "ModuleNotFoundError: No module named 'lib'"
**L√∂sung**: Virtual Environment aktivieren:
```bash
source venv/bin/activate
pip install -r requirements.txt
```

### Problem: "Connection refused" bei Ollama
**L√∂sung**: Ollama Service starten:
```bash
ollama serve  # Oder: systemctl start ollama
```

### Problem: SSL-Fehler beim Start
**L√∂sung**: Zertifikate pr√ºfen oder HTTP nutzen:
```bash
# Zertifikate pr√ºfen
ls -la ssl/

# Oder: Ohne SSL testen (Code f√§llt auf HTTP zur√ºck)
```

### Problem: SearXNG nicht erreichbar
**L√∂sung**: Docker Container pr√ºfen:
```bash
cd docker/searxng
docker compose ps
docker compose logs
```

### Problem: Piper TTS funktioniert nicht
**L√∂sung**: Auf Edge TTS umschalten (Cloud):
```bash
# In UI: Settings ‚Üí TTS Engine ‚Üí "Edge TTS (Cloud)"
# Oder: Piper Model herunterladen (siehe Schritt 6)
```

---

## üìä Portabilit√§ts-√úbersicht

| Komponente | Portabel? | Aktion n√∂tig |
|---|---|---|
| Python Code | ‚úÖ Ja | Keine |
| lib/ Module | ‚úÖ Ja | Keine |
| requirements.txt | ‚úÖ Ja | `pip install -r requirements.txt` |
| settings.json | ‚úÖ Ja | Wird automatisch migriert |
| Ollama Models | ‚ö†Ô∏è Neu pullen | `ollama pull <model>` |
| SearXNG Docker | ‚ö†Ô∏è Neu starten | `docker compose up -d` |
| SSL Zertifikate | ‚ùå Optional | Eigene Zertifikate oder ohne |
| Piper Model | ‚ùå Optional | Download oder Edge TTS nutzen |
| API Keys | ‚ùå Optional | `.env` neu erstellen |
| Systemd Service | ‚ùå Optional | Pfade anpassen |

---

## ‚úÖ Minimale Portierung (ohne optionale Features)

**Was du wirklich brauchst:**
1. Repository klonen
2. Virtual Environment + Dependencies
3. Ollama installieren + Models pullen
4. SearXNG Docker starten
5. `python aifred_intelligence.py` ausf√ºhren

**Alles andere ist optional!**
- SSL: Nur f√ºr HTTPS n√∂tig
- Piper: Nur f√ºr lokales TTS n√∂tig (Edge TTS funktioniert ohne)
- API Keys: Nur f√ºr Brave/Tavily n√∂tig (SearXNG funktioniert ohne)
- Systemd: Nur f√ºr Autostart n√∂tig

---

**üé© AIfred Intelligence - AI at your service**
