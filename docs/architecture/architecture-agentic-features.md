# Architektur: Agentische Erweiterungen f√ºr Voice Assistant

**Version:** 1.0
**Datum:** 2025-10-13
**Status:** Planung

---

## üéØ Ziel

Erweitere den AI Voice Assistant um agentische F√§higkeiten:
- üîç **Web-Suche** - Echtzeit-Informationen aus dem Internet (DuckDuckGo)
- üì∞ **Internet-Recherche** - Multi-Source-Aggregation mit Web-Scraping
- ü§ñ **Interaktiver Agent-Modus** - User w√§hlt zwischen Web-Recherche und eigenem Wissen
- üéöÔ∏è **Recherche-Tiefe w√§hlbar** - Schnell (nur DuckDuckGo) oder Ausf√ºhrlich (+ Web-Scraping)
- üß† **Context-Enrichment** - Anreicherung von Antworten mit aktuellen Daten
- üîí **Privacy-First** - DuckDuckGo als privacy-freundliche Suchmaschine

---

## üìã Bestehende Architektur

### Aktuelle Pipeline (3 Stufen)

```
[Audio Input] ‚Üí [STT (Whisper)] ‚Üí [AI Inference (Ollama)] ‚Üí [TTS (Edge/Piper)] ‚Üí [Audio Output]
     ‚Üì                ‚Üì                      ‚Üì                        ‚Üì
  Audio File      User Text              AI Text                Audio File
  + Zeit          + Zeit                 + Zeit                 + Zeit
```

**Vorteile:**
- ‚úÖ Klare Trennung der Verarbeitungsstufen
- ‚úÖ Performance-Tracking auf jeder Stufe
- ‚úÖ Robuste State-Management
- ‚úÖ Gradio Event-Chaining

**Limitierungen f√ºr Agenten:**
- ‚ùå Keine Tool-Integration
- ‚ùå Keine Web-Suche
- ‚ùå Keine Multi-Step-Reasoning
- ‚ùå Keine externe Daten-Quellen

---

## üèóÔ∏è Geplante Architektur: Agentische Pipeline

### Neue 5-Stufen-Pipeline mit Agent-Layer

```
[Audio Input]
    ‚Üì
[STT (Whisper)] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí User Text + STT Zeit
    ‚Üì
[Intent Detection] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Intent: direct_answer | web_search | research | tool_call
    ‚Üì
    ‚îú‚îÄ [Direct Path] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí AI Inference (Standard)
    ‚îÇ
    ‚îú‚îÄ [Agent Path]
    ‚îÇ   ‚îú‚îÄ [Tool Selection] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Welche Tools ben√∂tigt?
    ‚îÇ   ‚îú‚îÄ [Tool Execution] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Web Search, API Calls, etc.
    ‚îÇ   ‚îÇ   ‚îú‚îÄ Web Search (DuckDuckGo/SearxNG)
    ‚îÇ   ‚îÇ   ‚îú‚îÄ Web Scraping (BeautifulSoup/Playwright)
    ‚îÇ   ‚îÇ   ‚îú‚îÄ Fact Checking (Multi-Source)
    ‚îÇ   ‚îÇ   ‚îî‚îÄ Data Aggregation
    ‚îÇ   ‚îî‚îÄ [Context Building] ‚îÄ‚îÄ‚îÄ‚Üí Kontext aus Tool-Ergebnissen
    ‚îÇ
    ‚îî‚îÄ [AI Inference + Context] ‚îÄ‚Üí AI Text + Inferenz Zeit
         ‚Üì
[TTS (Edge/Piper)] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Audio File + TTS Zeit
    ‚Üì
[Audio Output]
```

---

## üí° Interaktiver Agent-Modus (User-Choice)

### Konzept: User entscheidet

Statt automatischer Agent-Aktivierung bieten wir dem User **Wahlm√∂glichkeiten** an:

#### **Flow 1: Agent-Nutzung w√§hlen**

```
User: "Was sind die neuesten Entwicklungen in der KI?"
  ‚Üì
[Intent Detection erkennt: K√∂nnte aktuelle Infos ben√∂tigen]
  ‚Üì
ü§ñ Agent fragt nach:
  "M√∂chtest du, dass ich dazu im Web recherchiere,
   oder soll ich mit meinem vorhandenen Wissen antworten?

   [üåê Web-Recherche] [üß† Eigenes Wissen]"
  ‚Üì
User klickt: [üåê Web-Recherche]
  ‚Üì
‚Üí Weiter zu Flow 2 (Recherche-Tiefe)
```

#### **Flow 2: Recherche-Tiefe w√§hlen**

```
ü§ñ Agent fragt nach:
  "Welche Art von Recherche?

   [‚ö° Schnell (nur DuckDuckGo, ~3s)]
   [üîç Ausf√ºhrlich (DuckDuckGo + Web-Scraping, ~10s)]"
  ‚Üì
User w√§hlt: [üîç Ausf√ºhrlich]
  ‚Üì
Agent arbeitet:
  1. DuckDuckGo Suche ‚Üí Top 3-5 URLs
  2. Web Scraping ‚Üí Content von URLs extrahieren
  3. Context Building ‚Üí AI-freundlich formatieren
  4. AI Inference ‚Üí Antwort mit Quellen
  ‚Üì
Antwort: "Basierend auf 3 Quellen (Wikipedia, ArXiv, Tech-Blog):
          Die neuesten KI-Entwicklungen umfassen..."
```

#### **Alternative: User w√§hlt "Eigenes Wissen"**

```
User klickt: [üß† Eigenes Wissen]
  ‚Üì
Standard-Pipeline:
  AI Inference (ohne Web-Context) ‚Üí Antwort aus Ollama-Wissen
  ‚Üì
Antwort: "Basierend auf meinem Wissen bis Januar 2025:
          KI-Entwicklungen umfassen..."
```

### UI-Implementierung (Gradio)

#### **Modus-Auswahl in Settings (Sauber & √úbersichtlich)**

User w√§hlt den Recherche-Modus in den Einstellungen - spart Platz im Haupt-Interface!

```python
# In den Einstellungen (ganz unten mit den anderen Settings)
with gr.Row():
    with gr.Column():
        gr.Markdown("### ü§ñ Agent-Einstellungen")

        # Recherche-Modus Auswahl (Radio-Buttons, immer sichtbar)
        research_mode = gr.Radio(
            choices=[
                "üß† Eigenes Wissen (schnell)",
                "‚ö° Web-Suche Schnell (mittel)",
                "üîç Web-Suche Ausf√ºhrlich (langsam)",
                "ü§ù Interaktiv (variabel)"
            ],
            value="‚ö° Web-Suche Schnell (mittel)",  # Default: Aktuell & schnell
            label="üéØ Recherche-Modus",
            info="W√§hle, wie der Assistant Fragen beantwortet"
        )

        # Accordion mit Erkl√§rungen (zugeklappt, optional)
        with gr.Accordion("‚ÑπÔ∏è Was bedeuten die Modi?", open=False):
            gr.Markdown("""
            **üß† Eigenes Wissen** - Schnell, offline, AI-Wissen (Stand: Jan 2025)

            **‚ö° Web-Suche Schnell** - Mittel, DuckDuckGo (1 Quelle), privacy-freundlich

            **üîç Web-Suche Ausf√ºhrlich** - Langsam, 3-5 Quellen analysiert, gr√ºndlich

            **ü§ù Interaktiv** - Variabel, du w√§hlst bei jeder Frage neu

            ---

            **Weitere Details:**
            - **Search Engine:** DuckDuckGo (keine Cookies, kein Tracking)
            - **Web-Scraping:** Nur bei "Ausf√ºhrlich"-Modus
            - **Offline-F√§higkeit:** Nur bei "Eigenes Wissen"
            """)
```

**Vorteile dieser L√∂sung:**
- ‚úÖ **Kompakt:** Accordion standardm√§√üig zugeklappt ‚Üí spart Platz
- ‚úÖ **Mobile-optimiert:** Nur 1 Zeile (Accordion-Header) wenn zu
- ‚úÖ **Informativ:** Alle Details verf√ºgbar wenn User sie braucht
- ‚úÖ **Haupt-UI clean:** Nur Radio-Buttons sichtbar
- ‚úÖ **Settings persistiert:** In `assistant_settings.json`
- ‚úÖ **Intuitiv:** Standard-Pattern (Accordion) bekannt aus vielen UIs
- ‚úÖ **4 Modi:** Inkl. "Interaktiv" f√ºr maximale Flexibilit√§t

#### **Submit mit gew√§hltem Modus**

```python
# Audio Submit verwendet den gew√§hlten Modus
audio_submit.click(
    # Stufe 1: STT
    chat_audio_step1_transcribe,
    inputs=[audio_input, whisper_model],
    outputs=[user_text, stt_time_state]
).then(
    # Stufe 2: AI mit Modus-basiertem Routing
    chat_audio_step2_with_mode,
    inputs=[
        user_text,
        stt_time_state,
        current_mode,  # ‚Üê √úbergibt gew√§hlten Modus
        model,
        history
    ],
    outputs=[ai_text, history, inference_time_state]
).then(
    # Stufe 3: TTS
    chat_audio_step3_tts,
    inputs=[ai_text, ...],
    outputs=[audio_output, history]
)
```

#### **Status-Anzeige w√§hrend Recherche**

```python
agent_status = gr.Markdown("ü§ñ Agent Status: Bereit", visible=True)

# Updates w√§hrend Recherche:
# "ü§ñ Recherchiere mit DuckDuckGo... üîç"
# "ü§ñ Scrape 3 Webseiten... üìÑ"
# "ü§ñ Baue Context f√ºr AI... üß©"
# "ü§ñ Generiere Antwort... üí¨"
```

### Vorteile des Interaktiven Modus

1. **User-Kontrolle**
   - User entscheidet bewusst √ºber Web-Zugriff
   - Transparenz √ºber Datenquellen

2. **Performance-Wahl**
   - Schnelle Antwort vs. Ausf√ºhrliche Recherche
   - User kann Zeit-Komplexit√§t-Tradeoff selbst w√§hlen

3. **Privacy-Bewusstsein**
   - User wei√ü, wann externe APIs kontaktiert werden
   - Opt-In statt Opt-Out

4. **Fallback-Sicherheit**
   - Bei Web-API-Fehlern: Immer Fallback zu "Eigenes Wissen"
   - Keine h√§ngenden Anfragen

5. **Learning Experience**
   - User lernt, wann Agent-Recherche sinnvoll ist
   - Feedback √ºber Recherche-Qualit√§t

### Settings: Persistierung & Laden

```python
# Default Settings erweitern
DEFAULT_SETTINGS = {
    "model": "llama3.2:3b",
    "voice": "Deutsch (Katja)",
    "tts_speed": 1.25,
    "enable_tts": True,
    "tts_engine": "Edge TTS (Cloud, beste Qualit√§t)",
    "whisper_model": "base (142MB, schnell, multilingual)",
    # Neu: Agent Settings
    "research_mode": "‚ö° Web-Suche Schnell (mittel)"  # Default: Aktuell & schnell
}

def save_settings(..., research_mode):
    """Speichert Settings inkl. research_mode"""
    settings = {
        ...
        "research_mode": research_mode
    }
    with open(SETTINGS_FILE, 'w', encoding='utf-8') as f:
        json.dump(settings, f, indent=2, ensure_ascii=False)

# Settings-Change Handler
research_mode.change(
    save_settings,
    inputs=[model, voice, tts_speed, enable_tts, tts_engine, whisper_model, research_mode]
)
```

**Settings werden gespeichert in:** `assistant_settings.json`

```json
{
  "model": "llama3.2:3b",
  "voice": "Deutsch (Katja)",
  "tts_speed": 1.25,
  "enable_tts": true,
  "tts_engine": "Edge TTS (Cloud, beste Qualit√§t)",
  "whisper_model": "base (142MB, schnell, multilingual)",
  "research_mode": "‚ö° Web-Suche Schnell (mittel)"
}
```

### Technische Implementation

#### **Modus-basiertes Routing (Einfach & Klar)**

Da User den Modus in Settings w√§hlt, brauchen wir keine Intent-Detection mehr!

```python
def chat_audio_step2_with_mode(
    user_text: str,
    stt_time: float,
    research_mode: str,  # Gew√§hlter Modus aus Settings
    model_choice: str,
    history: list
) -> tuple:
    """
    Routet basierend auf gew√§hltem Modus (aus Settings)

    Returns:
        (ai_text, history, inference_time, agent_time)
    """

    # Parse Modus
    if "Eigenes Wissen" in research_mode:
        # Standard-Pipeline ohne Agent
        return chat_audio_step2_ai(
            user_text, stt_time, model_choice, None, None, True, "Edge TTS", history
        )

    elif "Schnell" in research_mode:
        # Web-Suche nur mit DuckDuckGo
        return perform_agent_research(user_text, stt_time, "quick", model_choice, history)

    elif "Ausf√ºhrlich" in research_mode:
        # Web-Suche + Web-Scraping
        return perform_agent_research(user_text, stt_time, "deep", model_choice, history)

    else:
        # Fallback: Eigenes Wissen
        return chat_audio_step2_ai(
            user_text, stt_time, model_choice, None, None, True, "Edge TTS", history
        )
```

**Vorteil:** Keine komplexe Intent-Detection n√∂tig - User hat bereits gew√§hlt!

#### **Research-Execution (Schnell vs. Ausf√ºhrlich)**

```python
def perform_agent_research(
    user_text: str,
    research_depth: str,  # "quick" | "deep"
    model_choice: str,
    history: list
) -> tuple:
    """
    F√ºhrt Agent-Recherche durch
    """
    agent_start = time.time()
    tool_results = []

    # 1. DuckDuckGo Suche (immer)
    ddg_tool = DuckDuckGoSearchTool()
    ddg_result = ddg_tool.execute(user_text)
    tool_results.append(ddg_result)

    # 2. Web Scraping (nur bei "deep")
    if research_depth == "deep" and ddg_result.get('urls'):
        scraper_tool = WebScraperTool()
        for url in ddg_result['urls'][:3]:  # Top 3 URLs
            scraped = scraper_tool.execute(url)
            if scraped:
                tool_results.append(scraped)

    # 3. Context Building
    context = build_context(user_text, tool_results)

    # 4. AI Inference
    messages = [{'role': 'system', 'content': context}]
    messages.append({'role': 'user', 'content': user_text})

    inference_start = time.time()
    response = ollama.chat(model=model_choice, messages=messages)
    inference_time = time.time() - inference_start

    agent_time = time.time() - agent_start

    ai_text = response['message']['content']

    # History mit Research-Info
    sources_count = len(tool_results)
    research_label = "Schnell" if research_depth == "quick" else "Ausf√ºhrlich"
    user_with_time = f"{user_text} (STT: {stt_time:.1f}s, Agent: {agent_time:.1f}s, {research_label}, {sources_count} Quellen)"

    history.append([user_with_time, ai_text])

    return ai_text, history, inference_time, agent_time
```

---

## üîß Technische Komponenten

### 1. Intent Detection Layer

**Funktion:** Erkennt, ob die User-Anfrage Tools ben√∂tigt

**Implementation:**
```python
def detect_intent(user_text: str) -> dict:
    """
    Analysiert User-Anfrage und erkennt Intent

    Returns:
        {
            'intent': 'direct_answer' | 'web_search' | 'research' | 'tool_call',
            'tools_needed': ['web_search', 'scraper', ...],
            'keywords': ['Python', 'Tutorial', ...],
            'reasoning': 'User fragt nach aktuellen Informationen...'
        }
    """
```

**Erkennungs-Strategien:**
1. **Keyword-basiert** (schnell)
   - "aktuelle", "neueste", "heute", "jetzt" ‚Üí Web-Suche
   - "suche", "finde", "recherchiere" ‚Üí Research
   - "wetter", "b√∂rse", "nachrichten" ‚Üí API-Call

2. **LLM-basiert** (pr√§zise)
   - Kleines lokales Modell (llama3.2:1b) klassifiziert Intent
   - Prompt: "Brauch ich Web-Suche f√ºr: {user_text}? Antworte nur ja/nein"

3. **Hybrid** (empfohlen)
   - Keywords als Fast-Path
   - LLM f√ºr unklare F√§lle

**Performance:**
- Target: < 100ms f√ºr Intent Detection
- Keywords: ~10ms
- LLM (1b): ~50-100ms

---

### 2. Agent-Tool-System

#### Tool-Architektur

```python
class BaseTool:
    """Base class f√ºr alle Agent-Tools"""
    def __init__(self):
        self.name = ""
        self.description = ""

    def execute(self, query: str, **kwargs) -> dict:
        """F√ºhrt Tool aus und gibt Ergebnis zur√ºck"""
        raise NotImplementedError

class WebSearchTool(BaseTool):
    """Web-Suche via DuckDuckGo oder SearxNG"""

class WebScraperTool(BaseTool):
    """Extrahiert Content von Webseiten"""

class FactCheckTool(BaseTool):
    """Verifiziert Informationen aus mehreren Quellen"""

class NewsAggregatorTool(BaseTool):
    """Sammelt aktuelle Nachrichten zu einem Thema"""
```

#### Verf√ºgbare Tools (Phase 1)

##### 1. **WebSearchTool** - DuckDuckGo Instant Answer API

**Quelle:** https://api.duckduckgo.com/
**Vorteil:** Kostenlos, keine API-Keys, Rate-Limit-freundlich
**Nachteil:** Begrenzte Ergebnisse (meist nur Top-1 Antwort)

```python
import requests

def search_duckduckgo(query: str) -> dict:
    """
    DuckDuckGo Instant Answer API

    Returns:
        {
            'answer': 'Python is a programming language...',
            'abstract': 'L√§ngerer Text...',
            'url': 'https://wikipedia.org/...',
            'source': 'Wikipedia'
        }
    """
    url = "https://api.duckduckgo.com/"
    params = {
        'q': query,
        'format': 'json',
        'no_html': 1,
        'skip_disambig': 1
    }
    response = requests.get(url, params=params, timeout=5)
    return response.json()
```

**Use Cases:**
- Faktenfragen: "Was ist Python?"
- Definitionen: "Was bedeutet Machine Learning?"
- Schnelle Infos: "Hauptstadt von Frankreich?"

**Performance:** ~500ms - 2s

---

##### 2. **WebSearchTool** - SearxNG (Self-Hosted, optional)

**Quelle:** Eigene SearxNG-Instanz oder √∂ffentliche Instanz
**Vorteil:** Privacy, aggregiert mehrere Suchmaschinen, volle Kontrolle
**Nachteil:** Ben√∂tigt Setup/Hosting

```python
def search_searxng(query: str, searx_url: str = "https://searx.be") -> list:
    """
    SearxNG Meta-Suchmaschine

    Returns:
        [
            {
                'title': 'Python Tutorial',
                'url': 'https://...',
                'content': 'Beschreibung...',
                'engine': 'google'
            },
            ...
        ]
    """
    url = f"{searx_url}/search"
    params = {
        'q': query,
        'format': 'json',
        'categories': 'general'
    }
    response = requests.get(url, params=params, timeout=10)
    return response.json()['results']
```

**Use Cases:**
- Multi-Source-Recherche
- Privacy-sensitive Anfragen
- Aggregierte Ergebnisse

**Performance:** ~2-5s (aggregiert mehrere Quellen)

---

##### 3. **WebScraperTool** - BeautifulSoup (leichtgewichtig)

**Funktion:** Extrahiert Text-Content von Webseiten

```python
from bs4 import BeautifulSoup
import requests

def scrape_webpage(url: str, max_chars: int = 5000) -> dict:
    """
    Extrahiert Haupt-Content einer Webseite

    Returns:
        {
            'title': 'Seitentitel',
            'content': 'Haupttext...',
            'url': 'https://...',
            'word_count': 1234
        }
    """
    response = requests.get(url, timeout=10, headers={
        'User-Agent': 'Mozilla/5.0 (AI Voice Assistant Bot)'
    })
    soup = BeautifulSoup(response.text, 'html.parser')

    # Entferne Skripte, Styles, Navigation
    for tag in soup(['script', 'style', 'nav', 'footer', 'header']):
        tag.decompose()

    # Extrahiere Text
    text = soup.get_text(separator=' ', strip=True)

    # K√ºrze auf max_chars
    if len(text) > max_chars:
        text = text[:max_chars] + "..."

    return {
        'title': soup.title.string if soup.title else '',
        'content': text,
        'url': url,
        'word_count': len(text.split())
    }
```

**Use Cases:**
- Content-Extraktion von Such-Ergebnissen
- Artikel-Zusammenfassung
- Detailierte Recherche

**Performance:** ~1-3s pro Seite

**Limitierungen:**
- Keine JavaScript-Rendering (statisches HTML only)
- Blockiert von manchen Sites (Rate-Limiting, Cloudflare)

---

##### 4. **NewsAggregatorTool** - NewsAPI (optional, API-Key)

**Quelle:** https://newsapi.org/ (Free Tier: 100 requests/day)

```python
def fetch_news(query: str, api_key: str, language: str = 'de') -> list:
    """
    Holt aktuelle Nachrichten zu einem Thema

    Returns:
        [
            {
                'title': 'Nachrichtentitel',
                'description': 'Kurzbeschreibung...',
                'url': 'https://...',
                'source': 'Tagesschau',
                'published_at': '2025-10-13T10:00:00Z'
            },
            ...
        ]
    """
    url = "https://newsapi.org/v2/everything"
    params = {
        'q': query,
        'apiKey': api_key,
        'language': language,
        'sortBy': 'publishedAt',
        'pageSize': 5
    }
    response = requests.get(url, params=params, timeout=10)
    return response.json()['articles']
```

**Alternative (kostenlos):** RSS-Feeds von Tagesschau, Spiegel, etc.

---

### 3. Context Builder

**Funktion:** Erstellt optimierten Kontext f√ºr AI aus Tool-Ergebnissen

```python
def build_context(user_text: str, tool_results: list) -> str:
    """
    Baut strukturierten Kontext f√ºr AI aus Tool-Ergebnissen

    Args:
        user_text: Urspr√ºngliche User-Frage
        tool_results: Liste von Tool-Outputs

    Returns:
        Formatierter Kontext-String f√ºr AI
    """
    context = f"# User-Frage: {user_text}\n\n"
    context += "# Recherche-Ergebnisse:\n\n"

    for i, result in enumerate(tool_results, 1):
        context += f"## Quelle {i}: {result.get('source', 'Unbekannt')}\n"
        context += f"{result.get('content', '')}\n\n"

    context += "# Aufgabe:\n"
    context += "Beantworte die User-Frage basierend auf den Recherche-Ergebnissen. "
    context += "Zitiere Quellen wenn m√∂glich. Sei pr√§zise und fasse zusammen.\n"

    return context
```

**Strategie:**
1. Tool-Ergebnisse sammeln
2. Nach Relevanz sortieren
3. Auf Token-Limit optimieren (llama3.2:3b ‚Üí 8K context window)
4. Formatieren f√ºr optimale AI-Nutzung

---

### 4. Agent-Pipeline-Integration

**Neue Funktion:** `chat_audio_step2_agent_ai()`

Ersetzt `chat_audio_step2_ai()` bei Agent-Anfragen:

```python
def chat_audio_step2_agent_ai(
    user_text: str,
    stt_time: float,
    model_choice: str,
    history: list
) -> tuple:
    """
    Agentische AI-Antwort mit Tool-Integration

    Pipeline:
        1. Intent Detection
        2. Tool Selection & Execution
        3. Context Building
        4. AI Inference mit Context

    Returns:
        (ai_text, history, inference_time, agent_time, tools_used)
    """

    # 1. Intent Detection
    intent = detect_intent(user_text)

    if intent['intent'] == 'direct_answer':
        # Fallback zu Standard-Pipeline
        return chat_audio_step2_ai(...)

    # 2. Tool Execution
    agent_start = time.time()
    tool_results = []

    for tool_name in intent['tools_needed']:
        tool = get_tool(tool_name)
        result = tool.execute(user_text, keywords=intent['keywords'])
        tool_results.append(result)

    # 3. Context Building
    context = build_context(user_text, tool_results)

    # 4. AI Inference mit Context
    messages = [{'role': 'system', 'content': context}]
    # ... History hinzuf√ºgen ...
    messages.append({'role': 'user', 'content': user_text})

    inference_start = time.time()
    response = ollama.chat(model=model_choice, messages=messages)
    inference_time = time.time() - inference_start

    agent_time = time.time() - agent_start

    ai_text = response['message']['content']

    # History mit Agent-Info
    tools_str = ", ".join(intent['tools_needed'])
    user_with_time = f"{user_text} (STT: {stt_time:.1f}s, Agent: {agent_time:.1f}s, Tools: {tools_str})"

    history.append([user_with_time, ai_text])

    return ai_text, history, inference_time, agent_time, intent['tools_needed']
```

---

## üé® UI/UX Erweiterungen

### 1. Agent-Status-Anzeige

**Neue UI-Komponenten:**

```python
with gr.Row():
    agent_status = gr.Markdown("ü§ñ Agent Status: Bereit", visible=True)
    agent_progress = gr.HTML("", visible=False)  # Fortschrittsanzeige
```

**Live-Updates w√§hrend Agent-Arbeit:**

```
ü§ñ Agent Status: Suche Web-Informationen... üîç
ü§ñ Agent Status: Analysiere 3 Quellen... üìä
ü§ñ Agent Status: Generiere Antwort... üí¨
```

### 2. Timing-Anzeige erweitern

**Vorher:**
```
User: Wie wird das Wetter? (STT: 1.2s)
AI: Ich kann leider keine Live-Wetterdaten abrufen. (Inferenz: 2.3s, TTS: 1.5s)
```

**Nachher (mit Agent):**
```
User: Wie wird das Wetter in Berlin? (STT: 1.2s, Agent: 3.5s, Tools: web_search)
AI: Aktuell 15¬∞C in Berlin, bew√∂lkt. Quelle: DuckDuckGo. (Inferenz: 2.3s, TTS: 1.5s)
```

### 3. Settings: Agent An/Aus

```python
enable_agent = gr.Checkbox(
    value=True,
    label="ü§ñ Agentische F√§higkeiten aktiviert",
    info="Erm√∂glicht Web-Suche und Internet-Recherche"
)

agent_tools = gr.CheckboxGroup(
    choices=["Web-Suche (DuckDuckGo)", "Web-Scraping", "News-Aggregation"],
    value=["Web-Suche (DuckDuckGo)"],
    label="üõ†Ô∏è Verf√ºgbare Agent-Tools",
    info="W√§hle, welche Tools der Agent nutzen darf"
)
```

---

## üìä Performance-Ziele

| Komponente | Target Latenz | Akzeptabel | Kritisch |
|-----------|---------------|------------|----------|
| Intent Detection | < 100ms | < 200ms | > 500ms |
| Web Search (DDG) | < 2s | < 5s | > 10s |
| Web Scraping (pro URL) | < 3s | < 7s | > 15s |
| Context Building | < 100ms | < 300ms | > 1s |
| AI Inference (mit Context) | < 5s | < 10s | > 20s |
| **Gesamt (Schnell-Modus)** | **< 5s** | **< 8s** | **> 15s** |
| **Gesamt (Ausf√ºhrlich-Modus)** | **< 12s** | **< 20s** | **> 30s** |

**Vergleich der Modi:**

| Modus | Komponenten | Gesch√§tzte Zeit |
|-------|-------------|-----------------|
| **Standard** (ohne Agent) | STT + AI + TTS | ~3-5s |
| **Schnell** (nur DDG) | STT + Intent + DDG + AI + TTS | ~5-8s |
| **Ausf√ºhrlich** (DDG + Scraping) | STT + Intent + DDG + Scrape (3x) + AI + TTS | ~12-20s |

**Breakdown Ausf√ºhrlich-Modus (Beispiel):**
- STT: 1s
- Intent Detection: 0.1s
- DuckDuckGo: 2s
- Web Scraping (3 URLs): 3-9s (parallel m√∂glich!)
- Context Building: 0.2s
- AI Inference: 3-5s
- TTS: 2s
- **Gesamt:** ~11-20s

**Optimierungen:**
1. **Caching** - H√§ufige Anfragen cachen (Redis/In-Memory)
2. **Parallel Execution** - Tools parallel ausf√ºhren
3. **Streaming** - AI-Antwort streamen w√§hrend TTS l√§uft
4. **Timeout** - Tools nach 10s abbrechen

---

## üîê Sicherheit & Privacy

### 1. Rate Limiting

```python
from functools import lru_cache
import time

# Simple In-Memory Rate Limiter
tool_call_times = {}

def rate_limit(tool_name: str, max_calls_per_minute: int = 10):
    now = time.time()
    if tool_name not in tool_call_times:
        tool_call_times[tool_name] = []

    # Entferne alte Eintr√§ge (> 60s)
    tool_call_times[tool_name] = [
        t for t in tool_call_times[tool_name]
        if now - t < 60
    ]

    if len(tool_call_times[tool_name]) >= max_calls_per_minute:
        raise Exception(f"Rate limit erreicht f√ºr {tool_name}")

    tool_call_times[tool_name].append(now)
```

### 2. URL Whitelisting (optional)

```python
ALLOWED_DOMAINS = [
    'wikipedia.org',
    'github.com',
    'stackoverflow.com',
    # ... trusted sources
]

def is_url_allowed(url: str) -> bool:
    from urllib.parse import urlparse
    domain = urlparse(url).netloc
    return any(domain.endswith(allowed) for allowed in ALLOWED_DOMAINS)
```

### 3. Content Filtering

```python
def sanitize_content(text: str) -> str:
    """Entfernt sensible Daten aus Web-Content"""
    # Entferne potenzielle Skripte
    text = re.sub(r'<script.*?</script>', '', text, flags=re.DOTALL)
    # Entferne Email-Adressen (optional)
    # text = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '[EMAIL]', text)
    return text
```

---

## üì¶ Dependencies (Neue Pakete)

```bash
# Aktuelle Requirements
pip install gradio faster-whisper ollama edge-tts

# Neue Requirements f√ºr Agent-Features
pip install beautifulsoup4      # Web Scraping
pip install requests            # HTTP Requests
pip install lxml                # HTML Parsing (schneller als html.parser)

# Optional (f√ºr erweiterte Features)
pip install playwright          # JavaScript-rendering f√ºr komplexe Sites
pip install feedparser          # RSS Feed Parsing f√ºr News
pip install redis               # Caching Layer
```

**Datei√§nderung:** [requirements.txt](../requirements.txt) aktualisieren

---

## üöÄ Implementierungs-Phasen

### **Phase 1: Foundation (Woche 1-2)**

**Ziele:**
- ‚úÖ Intent Detection implementieren
- ‚úÖ Tool-System Grundger√ºst
- ‚úÖ DuckDuckGo Web-Search Integration
- ‚úÖ Basis Agent-Pipeline

**Deliverables:**
1. `agent_tools.py` - Tool-System
2. `intent_detector.py` - Intent Detection
3. `mobile_voice_assistant.py` - Erweitert mit Agent-Path
4. Testing: Einfache Web-Suche-Anfragen

**Test-Fragen:**
- "Was ist Python?"
- "Wie wird das Wetter heute?"
- "Aktuelle Nachrichten zu AI"

---

### **Phase 2: Advanced Tools (Woche 3-4)**

**Ziele:**
- ‚úÖ Web Scraping (BeautifulSoup)
- ‚úÖ Multi-Source-Aggregation
- ‚úÖ Context-Optimierung
- ‚úÖ Caching Layer

**Deliverables:**
1. Erweitertes Tool-Set
2. Context Builder Optimierung
3. Performance-Tuning
4. Caching-Strategie

**Test-Fragen:**
- "Fasse diesen Artikel zusammen: [URL]"
- "Vergleiche Python und JavaScript basierend auf aktuellen Quellen"

---

### **Phase 3: UI/UX & Polish (Woche 5)**

**Ziele:**
- ‚úÖ Agent-Status UI
- ‚úÖ Settings-Erweiterung
- ‚úÖ Performance-Optimierung
- ‚úÖ Error Handling
- ‚úÖ Documentation

**Deliverables:**
1. Vollst√§ndiges Agent-UI
2. User-Guide f√ºr Agent-Features
3. Performance-Benchmarks
4. Deployment-Ready

---

## üìà Erfolgs-Metriken

### Quantitative Metriken

1. **Antwort-Qualit√§t:**
   - Fact-Check Pass-Rate: > 90%
   - Quellen-Zitation: > 80% der Antworten
   - User-Zufriedenheit: > 4/5 Sterne

2. **Performance:**
   - Durchschnittliche Agent-Latenz: < 10s
   - Cache-Hit-Rate: > 30%
   - Tool-Erfolgsrate: > 95%

3. **Usage:**
   - Agent-Nutzung: > 40% aller Anfragen
   - Tool-Verteilung: Web-Search 70%, Scraping 20%, News 10%

### Qualitative Metriken

1. **User Experience:**
   - Agent-Antworten wirken "aktuell" und "fundiert"
   - Quellen-Transparenz erh√∂ht Vertrauen
   - Status-Updates geben Feedback w√§hrend Wartezeit

2. **Robustheit:**
   - Graceful Degradation bei Tool-Failures
   - Fallback zu Standard-Antworten funktioniert
   - Keine Crashes durch externe API-Fehler

---

## üîÑ Risiken & Mitigation

| Risiko | Wahrscheinlichkeit | Impact | Mitigation |
|--------|-------------------|--------|------------|
| Web-APIs offline | Mittel | Hoch | Fallback zu Standard-Antworten, Multi-Source |
| Rate-Limiting | Hoch | Mittel | Caching, eigene SearxNG-Instanz |
| Langsame Antworten | Mittel | Hoch | Timeout, Streaming, Performance-Tuning |
| Privacy-Bedenken | Niedrig | Hoch | Lokale Tools bevorzugen, User-Kontrolle |
| Content-Qualit√§t | Mittel | Mittel | Multi-Source Verification, Whitelisting |

---

## üìö Referenzen & Inspiration

### √Ñhnliche Projekte

1. **LangChain Agents:** https://python.langchain.com/docs/modules/agents/
   - Tool-Calling Patterns
   - Agent-Executors

2. **AutoGPT:** https://github.com/Significant-Gravitas/AutoGPT
   - Autonome Task-Execution

3. **Open Interpreter:** https://github.com/KillianLucas/open-interpreter
   - Local-First Agent-Architektur

### APIs & Services

1. **DuckDuckGo Instant Answer:** https://duckduckgo.com/api
2. **SearxNG:** https://github.com/searxng/searxng
3. **BeautifulSoup:** https://www.crummy.com/software/BeautifulSoup/
4. **NewsAPI:** https://newsapi.org/

---

## üìù N√§chste Schritte

### Sofort (diese Session):
1. ‚úÖ Architektur-Dokument fertigstellen
2. ‚è≥ README.md To-Do-Liste aktualisieren mit detaillierten Phase-1-Tasks
3. ‚è≥ `agent_tools.py` Grundger√ºst erstellen
4. ‚è≥ DuckDuckGo Web-Search Prototyp implementieren

### N√§chste Session:
1. Intent Detection implementieren
2. Agent-Pipeline in `mobile_voice_assistant.py` integrieren
3. Erste Tests mit Live Web-Search
4. UI Status-Updates

---

**Erstellt mit:** Claude Code
**Letzte Aktualisierung:** 2025-10-13
