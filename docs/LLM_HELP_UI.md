# LLM Model-Auswahl Hilfe (UI Version)

Diese Tabellen sind fÃ¼r die Anzeige in der Web-UI optimiert.

## ğŸ“Š SchnellÃ¼bersicht Tabelle (FÃ¼r UI Collapsible)

| Model | GrÃ¶ÃŸe | Empfehlung | Bester Einsatz |
|-------|-------|------------|----------------|
| **qwen2.5:14b** | 9 GB | â­â­â­â­â­ | **Web-Recherche, News** (nutzt NUR Recherche-Daten!) |
| **qwen3:8b** | 5.2 GB | â­â­â­â­ | Balance: Schnell + Gut |
| **command-r** | 18 GB | â­â­â­â­ | Enterprise RAG, Dokumente |
| **llama3.1:8b** | 4.9 GB | â­â­â­ | Allgemein, zuverlÃ¤ssig |
| **llama2:13b** | 7.4 GB | â­â­â­ | Breites Wissen, bewÃ¤hrt |
| **llama3.2:3b** | 2 GB | â­â­ | Tests, einfache Fragen |

---

**ğŸ† Top-Empfehlung fÃ¼r Web-Recherche:** `qwen2.5:14b`
- Ignoriert Training Data komplett (Score: 1.0)
- Nutzt NUR aktuelle Web-Ergebnisse
- Perfekt fÃ¼r: "Trump News", "aktuelle Ereignisse"

**âš¡ Schnellste Option:** `qwen3:8b` oder `llama3.1:8b`

**ğŸ“š Details:** Siehe [LLM_COMPARISON.md](LLM_COMPARISON.md)

---

## ğŸ“‹ Erweiterte Tabelle (FÃ¼r Dokumentation)

| Model | GrÃ¶ÃŸe | RAG | Tool-Use | Speed | RAM | Use-Case |
|-------|-------|-----|----------|-------|-----|----------|
| qwen2.5:14b | 9.0 GB | 1.0 ğŸ† | 0.95 | Mittel | ~12 GB | Web-Recherche, Agentic |
| qwen3:8b | 5.2 GB | 0.933 | 0.90 | Schnell | ~7 GB | Balance Speed/QualitÃ¤t |
| command-r | 18 GB | 0.92 | 0.95 | Langsam | ~22 GB | Enterprise RAG |
| llama3.1:8b | 4.9 GB | 0.85 | 0.88 | Schnell | ~6 GB | Allgemein, zuverlÃ¤ssig |
| llama2:13b | 7.4 GB | 0.78 | 0.82 | Mittel | ~10 GB | Legacy, Wissen |
| llama3.2:3b | 2.0 GB | ~0.70 | 0.75 | Sehr schnell | ~3 GB | Tests, einfach |

**Legende:**
- **RAG:** Context Adherence Score (1.0 = perfekt, nutzt nur Recherche)
- **Tool-Use:** Function Calling / Agent F1 Score
- **Speed:** Inferenz-Geschwindigkeit auf Mini-PC
- **RAM:** GeschÃ¤tzter Speicherverbrauch

---

## ğŸ¯ Use-Case Empfehlungen

### FÃ¼r dich (Voice Assistant mit Web-Recherche):
**Klar: qwen2.5:14b**

Warum?
1. âœ… Ignoriert Training Data komplett (Score: 1.0)
2. âœ… Nutzt NUR Web-Recherche Ergebnisse
3. âœ… LÃ¶st dein Problem: "AI nutzt 2022 Daten statt aktueller News"
4. âœ… Nicht zu groÃŸ (9 GB passt auf Mini-PC)
5. âœ… Beste Tool-Use fÃ¼r Agent-Calls (0.95)

### Falls Speed wichtiger:
**qwen3:8b**
- Schneller (kleiner)
- Immer noch sehr gut (0.933 RAG Score)
- Guter Kompromiss

### Nicht empfohlen fÃ¼r Web-Recherche:
- âŒ llama3.2:3b - Zu schwach, ignoriert Context oft
- âš ï¸ llama2:13b - Nutzt oft Training Data statt Recherche
- âš ï¸ command-r - Gut fÃ¼r RAG, aber 18 GB (evtl. zu langsam)

---

## ğŸ“Š Performance-Vergleich (Mini-PC)

| Model | Tokens/Sek | 100 WÃ¶rter Antwort | Startup Latenz |
|-------|------------|-------------------|----------------|
| llama3.2:3b | ~30-40 | ~5 Sek | ~1 Sek |
| qwen3:8b | ~15-25 | ~8 Sek | ~2 Sek |
| llama3.1:8b | ~15-25 | ~8 Sek | ~2 Sek |
| llama2:13b | ~10-15 | ~12 Sek | ~3 Sek |
| **qwen2.5:14b** | **~8-12** | **~15 Sek** | **~3 Sek** |
| command-r | ~5-10 | ~20+ Sek | ~5 Sek |

**Fazit:** qwen2.5:14b ist ~2x langsamer als llama3.2:3b, aber **10x besser** fÃ¼r RAG/Agentic!

FÃ¼r Voice Assistant ist 15 Sek OK (wÃ¤hrend User spricht ist eh Zeit).

---

## ğŸ§ª Context Adherence Test

**Test:** "Nutze nur bereitgestellte Recherche, nicht Training Data"

| Model | Verhalten | Beispiel |
|-------|-----------|----------|
| qwen2.5:14b | âœ… Perfekt | "Laut Quelle 1 (Tagesschau) vom 13.10.2025..." |
| qwen3:8b | âœ… Sehr gut | "Basierend auf der Recherche..." (manchmal Mix) |
| command-r | âœ… Gut | "Die bereitgestellten Quellen zeigen..." |
| llama3.1:8b | âš ï¸ Mittel | Mix aus Recherche + Training Data |
| llama2:13b | âš ï¸ Schwach | Oft Training Data, Recherche ignoriert |
| llama3.2:3b | âŒ Schlecht | Ignoriert Context hÃ¤ufig |

**Beispiel aus deinem Use-Case:**

**Frage:** "Neueste Nachrichten Ã¼ber Donald Trump"

**llama3.2:3b Antwort:**
> "Trump hat im Januar 2022 die Republikaner unterstÃ¼tzt..."
> âŒ Nutzt Training Data (2022), ignoriert Web-Recherche!

**qwen2.5:14b Antwort:**
> "Laut meiner aktuellen Recherche vom 13.10.2025 schreibt die Tagesschau, dass PrÃ¤sident Trump heute Nationalgardisten in Chicago einsetzen will..."
> âœ… Nutzt NUR Web-Recherche, zitiert korrekt!

---

## ğŸ’¾ Hardware-Anforderungen

### Dein Mini-PC (AOOSTAR GEM10, 32 GB RAM, 1TB M.2 SSD):
- âœ… llama3.2:3b (2 GB) - Kein Problem!
- âœ… qwen3:8b (5.2 GB) - Kein Problem!
- âœ… llama3.1:8b (4.9 GB) - Kein Problem!
- âœ… llama2:13b (7.4 GB) - Kein Problem!
- âœ… **qwen2.5:14b (9 GB)** â† Empfohlen! Kein Problem!
- âœ… **command-r (18 GB)** - LÃ¤uft perfekt mit 32 GB RAM! âœ…

**Fazit:** Dein System kann **ALLE** Modelle problemlos ausfÃ¼hren, sogar gleichzeitig mehrere! ğŸš€

### Hardware Specs:
- **System:** AOOSTAR GEM10 Mini PC
- **RAM:** 32 GB (mehr als genug fÃ¼r alle Models!)
- **Storage:** 1 TB M.2 SSD (viel Platz fÃ¼r alle Models)
- **Docker:** LÃ¤uft (SearXNG bereits installiert)

---

## ğŸš€ Finale Empfehlung

**FÃ¼r dich:** `qwen2.5:14b`

**Setup:**
1. In UI: Dropdown â†’ "qwen2.5:14b" auswÃ¤hlen
2. Recherche-Modus: "âš¡ Web-Suche Schnell"
3. Teste mit: "Zeige mir die neuesten Nachrichten Ã¼ber Trump"

**Erwartetes Verhalten:**
- âœ… AI nutzt Web-Recherche (SearXNG)
- âœ… AI sagt "Laut meiner aktuellen Recherche vom [heute]..."
- âœ… AI zitiert echte Quellen (Tagesschau, FAZ, etc.)
- âŒ AI sagt NICHT "Ich habe keinen Internet-Zugang"
- âŒ AI nutzt NICHT Training Data (2022/2023)

---

**Erstellt:** 2025-10-13
**Author:** Claude Code
**Version:** 1.0 - LLM Auswahl-Hilfe fÃ¼r Voice Assistant UI
